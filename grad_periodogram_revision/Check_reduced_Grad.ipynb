{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52db1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import norm, inv, det\n",
    "import time\n",
    "import seaborn as sns\n",
    "from multiprocess import Pool, cpu_count\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b607f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_exponential_hawkes(object):\n",
    "    \"\"\"\n",
    "    Multivariate Hawkes process with exponential kernel. No events nor initial conditions considered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, alpha, beta, max_jumps=None, max_time=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : array_like\n",
    "            Baseline intensity vector. mu.shape[0] must coincide with shapes for alpha and beta.\n",
    "        alpha : array_like\n",
    "            Interaction factors matrix. Must be a square array with alpha.shape[0] coinciding with mu and beta.\n",
    "        beta : array_like\n",
    "            Decay factor matrix. Must be either an array. When corresponding to decay for each process i, it must\n",
    "            be of shape (number_of_process, 1), or a square array. beta.shape[0] must coincide with mu and alpha.\n",
    "        max_jumps : float, optional\n",
    "            Maximal number of jumps. The default is None.\n",
    "        max_time : float, optional\n",
    "            Maximal time horizon. The default is None.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        nb_processes : int\n",
    "            Number of dimensions.\n",
    "        timestamps : list of tuple (float, int)\n",
    "            List of simulated events and their marks.\n",
    "        intensity_jumps : array of float\n",
    "            Array containing all intensities at each jump. It includes the baseline intensities mu.\n",
    "        simulated : bool\n",
    "            Parameter that marks if a process has been already been simulated,\n",
    "            or if its event times have been initialized.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # We must begin by verifying that the process is a point process. In other words, that the number of\n",
    "        # points in any bounded interval is a.s. finite. For this, we have to verify that the spectral radius of\n",
    "        # the matrix alpha/beta (term by term) is <1.\n",
    "\n",
    "        beta_radius = np.copy(beta)\n",
    "        beta_radius[beta_radius == 0] = 1\n",
    "        spectral_radius = np.max(np.abs(np.linalg.eig(np.abs(alpha) / beta_radius)[0]))\n",
    "\n",
    "        if spectral_radius >= 1:\n",
    "            # raise ValueError(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius))\n",
    "            warnings.warn(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius),RuntimeWarning)\n",
    "        self.mu = mu.reshape((alpha.shape[0], 1))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_jumps = max_jumps\n",
    "        self.max_time = max_time\n",
    "\n",
    "        self.nb_processes = self.mu.shape[0]\n",
    "        self.count = np.zeros(self.nb_processes, dtype=int)\n",
    "\n",
    "        self.timestamps = [(0.0, 0)]\n",
    "        self.intensity_jumps = np.copy(mu)\n",
    "\n",
    "        self.simulated = False\n",
    "\n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "        Auxiliary function to check if already simulated and, if not, which simulation to launch.\n",
    "\n",
    "        Simulation follows Ogata's adapted thinning algorithm. Upper bound obtained by the positive-part process.\n",
    "\n",
    "        Works with both self-exciting and self-regulating processes.\n",
    "\n",
    "        To launch simulation either self.max_jumps or self.max_time must be other than None, so the algorithm knows when to stop.\n",
    "        \"\"\"\n",
    "        if not self.simulated:\n",
    "            if self.max_jumps is not None and self.max_time is None:\n",
    "                self.simulate_jumps()\n",
    "            elif self.max_time is not None and self.max_jumps is None:\n",
    "                self.simulate_time()\n",
    "            else:\n",
    "                print(\"Either max_jumps or max_time must be given.\")\n",
    "            self.simulated = True\n",
    "\n",
    "        else:\n",
    "            print(\"Process already simulated\")\n",
    "\n",
    "    def simulate_jumps(self):\n",
    "        \"\"\"\n",
    "        Simulation is done until the maximal number of jumps (self.max_jumps) is attained.\n",
    "        \"\"\"\n",
    "        flag = 0\n",
    "        t = 0\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag < self.max_jumps:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1, np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            if type_event < self.nb_processes:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                flag += 1\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.max_time = self.timestamps[-1][0]\n",
    "        # Important to add the max_time for plotting and being consistent.\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def simulate_time(self):\n",
    "        \"\"\"\n",
    "        Simulation is done for a window [0, T] (T = self.max_time) is attained.\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        flag = t < self.max_time\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1,\n",
    "                                               np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            flag = t < self.max_time\n",
    "            if type_event < self.nb_processes and flag:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def plot_intensity(self, ax=None, plot_N=True, where=10):\n",
    "        \"\"\"\n",
    "        Plot intensity function. If plot_N is True, plots also step functions N^i([0,t]).\n",
    "        The parameter ax allows to plot the intensity function in a previously created plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : array of Axes, optional.\n",
    "            If None, method will generate own figure.\n",
    "            Otherwise, will use given axes. Must be array of shape (2,K) if plot_N = True, or (K,) if plot_N = False\n",
    "        plot_N : bool, optional.\n",
    "            Whether we plot the step function N^i or not.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.simulated:\n",
    "            print(\"Simulate first\")\n",
    "\n",
    "        else:\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            if plot_N:\n",
    "                jumps_plot = [[0] for i in range(self.nb_processes)]\n",
    "                if ax is None:\n",
    "                    fig, ax = plt.subplots(2, self.nb_processes, sharex=True)\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                elif isinstance(ax[0,0], matplotlib.axes.Axes):\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (2, number of processes+1)\"\n",
    "            else:\n",
    "                if ax is None:\n",
    "                    fig, ax1 = plt.subplots(1, self.nb_processes)\n",
    "                elif isinstance(ax, matplotlib.axes.Axes) or isinstance(ax, np.ndarray):\n",
    "                    ax1 = ax\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (number of processes+1,)\"\n",
    "\n",
    "            times = [0, self.timestamps[1][0]]\n",
    "            intensities = np.array([[self.mu[i, 0], self.mu[i, 0]] for i in range(self.nb_processes)])\n",
    "\n",
    "            ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "            step = 100\n",
    "            # print(\"here\", self.timestamps[len(self.timestamps)])\n",
    "\n",
    "            for i in range(1, len(self.timestamps[1:where])):\n",
    "                # On commence par mettre à jour la matrice lambda^{ij}\n",
    "                ij_intensity = np.multiply(ij_intensity,\n",
    "                                           np.exp(-self.beta * (self.timestamps[i][0] - self.timestamps[i - 1][0])))\n",
    "                # On enregistre le saut d'intensité de l'évenement, pour son type.\n",
    "                ij_intensity[:, self.timestamps[i][1]-1] += self.alpha[:, self.timestamps[i][1]-1]\n",
    "\n",
    "                # On définit la fonction à tracer entre T_n et T_{n+1}\n",
    "                func = lambda x: self.mu + np.matmul(\n",
    "                    np.multiply(ij_intensity, np.exp(-self.beta * (x - self.timestamps[i][0]))),\n",
    "                                np.ones((self.nb_processes, 1)))\n",
    "\n",
    "                # On enregistre la division de temps et les sauts\n",
    "                interval_t = np.linspace(self.timestamps[i][0], self.timestamps[i + 1][0], step)\n",
    "                times += interval_t.tolist()\n",
    "\n",
    "                intensities = np.concatenate((intensities, np.array(list(map(func, interval_t))).squeeze().T ), axis=1)\n",
    "                if plot_N:\n",
    "                    jumps_plot[self.timestamps[i][1]-1] += [self.timestamps[i][0] for t in range(2)]\n",
    "\n",
    "            for i in range(self.nb_processes):\n",
    "                ax1[i].plot(times, intensities[i], label=\"Underlying intensity\", c=\"#1f77b4\", linestyle=\"--\")\n",
    "                ax1[i].plot(times, np.maximum(intensities[i], 0), label=\"Conditional intensity\", c='r')\n",
    "                # ax1[i].plot([i for i,j in self.timestamps[:-1]], self.intensity_jumps[i,:], c='k', alpha=0.5)\n",
    "\n",
    "            ax1[0].legend()\n",
    "\n",
    "            if plot_N:\n",
    "                for i in range(self.nb_processes):\n",
    "                    jumps_plot[i] += [times[-1]]\n",
    "                    ax2[i].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"r\", label=\"Process #%s\"%(i+1))\n",
    "                    # ax2[i].set_ylim(ax2[i].get_ylim())\n",
    "                    for j in range(self.nb_processes):\n",
    "                        if j != i:\n",
    "                            ax2[j].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"#1f77b4\", alpha=0.5)\n",
    "\n",
    "                    ax2[i].legend()\n",
    "\n",
    "    def plot_heatmap(self, ax=None):\n",
    "        \"\"\"\n",
    "        This function allows to observe the heatmap where each cell {ij} corresponds to the value {alpha/beta} from that interaction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : .axes.Axes, optional.\n",
    "            If None, method will generate own ax.\n",
    "            Otherwise, will use given ax.\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        else:\n",
    "            ax = ax\n",
    "        beta_heat = np.copy(self.beta)\n",
    "        beta_heat[beta_heat == 0] = 1\n",
    "        heat_matrix = self.alpha/beta_heat\n",
    "\n",
    "        hex_list = ['#FF3333', '#FFFFFF', '#33FF49']\n",
    "\n",
    "        ax = sns.heatmap(heat_matrix, cmap=get_continuous_cmap(hex_list), center=0, ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5806730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_spectral_density(w, theta):\n",
    "    mu, alpha, beta = theta\n",
    "    dim = mu.shape[0]\n",
    "    mean_matrix = np.identity(dim) * (inv(np.identity(dim) - alpha + 1e-12) @ mu)\n",
    "    \n",
    "    fourier_matrix = alpha * beta / (beta - 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    return (spectral_matrix) @ mean_matrix @ np.conj(spectral_matrix.T)\n",
    "\n",
    "\n",
    "def spectral_multivariate_ll(theta, periodogram, K, max_time):\n",
    "    dim = int(np.sqrt(theta.shape[0] + 1) - 1)\n",
    "    theta_aux = (theta[:dim].reshape((dim, 1)), theta[dim:-dim].reshape((dim, dim)), theta[-dim:].reshape((dim, 1)))\n",
    "    f_matrixes = [multivariate_spectral_density(j/max_time, theta_aux) for j in range(1, K+1)]\n",
    "    ll = np.sum([np.trace(inv(f_matrixes[i]) @ periodogram[i]) + np.log(det(f_matrixes[i])) for i in range(0, K)])\n",
    "    return (1/max_time) * ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b5953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_periodogram_good(w, tList):\n",
    "    max_time = tList[-1][0]\n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    \n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    J_w = np.array([np.sum([np.exp(-2j * np.pi * w * t) for t in i]) for i in dimensional_times]).reshape((dim, 1))\n",
    "    return (1/max_time) * J_w @ np.conj(J_w.T)\n",
    "\n",
    "def multivariate_periodogram_bad(w, tList):\n",
    "    max_time = tList[-1][0]\n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    \n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    J_w = np.array([np.sum([np.exp(-2j * np.pi * w * t) for t in i]) for i in dimensional_times]).reshape((dim, 1))\n",
    "    return (1/max_time) * np.conj(J_w) @ (J_w.T)\n",
    "\n",
    "\n",
    "def multivariate_spectral_noised_density(w, theta):\n",
    "    mu, alpha, beta, noise = theta\n",
    "    dim = mu.shape[0]\n",
    "    mean_matrix = np.identity(dim) * (inv(np.identity(dim) - alpha + 1e-12) @ mu)\n",
    "    \n",
    "    fourier_matrix = alpha * beta / (beta + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    return spectral_matrix @ mean_matrix @ np.conj(spectral_matrix.T) + noise * np.identity(dim)\n",
    "\n",
    "\n",
    "def spectral_multivariate_noised_ll(theta, periodogram, K, max_time):\n",
    "    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "    theta_mid = theta[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "    f_matrixes = [multivariate_spectral_noised_density(j/max_time, theta_aux) for j in range(1, K+1)]\n",
    "    ll = np.sum([np.trace(inv(f_matrixes[i]) @ periodogram[i]) + np.log(det(f_matrixes[i])) for i in range(0, K)])\n",
    "    return (1/max_time) * ll.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c62932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_spectral_noised_single(w, theta): #alpha_21 != 0\n",
    "    mu, alpha, beta, noise = theta\n",
    "    #beta = np.array([beta_aux, 0]).reshape((2, 1))\n",
    "    dim = mu.shape[0]\n",
    "    m_1 = mu[0,0]\n",
    "    m_2 = mu[1,0] + m_1 * alpha\n",
    "    \n",
    "\n",
    "    f_11 = m_1 + noise\n",
    "    f_12 = m_1 * (alpha * beta)/(beta - 2j * np.pi * w)\n",
    "    f_21 = m_1 * (alpha * beta)/(beta + 2j * np.pi * w)\n",
    "    f_22 = m_1 * ((alpha * beta)**2)/(beta**2 + (2 * np.pi * w)**2) + m_2 + noise\n",
    "    return np.array([[f_11, f_12], [f_21, f_22]])\n",
    "\n",
    "\n",
    "def spectral_multivariate_noised_ll_single(theta, periodogram, K, max_time):\n",
    "    dim = 2\n",
    "    #theta_mid = theta[:-1]\n",
    "    theta_aux = (np.array(theta[:dim]).reshape((dim, 1)), \n",
    "                 theta[dim], \n",
    "                 theta[dim+1], \n",
    "                 theta[-1])\n",
    "    f_matrixes = [multivariate_spectral_noised_single(j/max_time, theta_aux) for j in range(1, K+1)]\n",
    "    ll = np.sum([np.trace(inv(f_matrixes[i]) @ periodogram[i]) + np.log(det(f_matrixes[i])) for i in range(0, K)])\n",
    "    return (1/max_time) * ll.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9954b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finufft\n",
    "def fast_multi_periodogram(K, tList, max_time, precision=1e-9):\n",
    "    \n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    # put K for w=0\n",
    "    aux = np.array([finufft.nufft1d1(2*np.pi*np.array(x)/max_time, np.ones(len(x)) + 0j, n_modes = 2*K+1, isign=-1, eps=1e-9)[K+1:] for x in dimensional_times]) \n",
    "    aux = (aux.T)[:,:, np.newaxis]\n",
    "    aux = (aux @ np.transpose(np.conj(aux), axes=(0,2,1))) / max_time\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f548b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei(size, index):\n",
    "    e = np.zeros((size))\n",
    "    e[index] = 1.0\n",
    "    return e\n",
    "\n",
    "def grad_completw(theta, w, periodogramw): #better version\n",
    "    mu0, alpha0, beta0, noise0 = theta\n",
    "    \n",
    "    dim = mu0.shape[0]\n",
    "    a = inv(np.identity(dim) - alpha0)\n",
    "    \n",
    "    mean_matrix = np.identity(dim) * (a @ mu0)\n",
    "    \n",
    "    fourier_matrix = alpha0 * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    \n",
    "    f_theta_unnoised = (spectral_matrix) @ mean_matrix @ np.conj(spectral_matrix.T)\n",
    "    f_theta = f_theta_unnoised + noise0 * np.identity(dim)\n",
    "    f_inv = inv(f_theta)\n",
    "    \n",
    "    ll = np.log(det(f_theta)) + np.trace(f_inv @ periodogramw)\n",
    "    \n",
    "    dmu = np.zeros((dim,dim,dim), dtype=np.complex128)\n",
    "    dalpha = np.zeros((dim, dim, dim, dim), dtype=np.complex128)\n",
    "    dbeta = np.zeros((dim, dim, dim), dtype=np.complex128)\n",
    "    aux_dbeta = alpha0 * (2j * np.pi * w) * np.repeat(1/(beta0 +  2j * np.pi * w)**2, dim, axis=1)\n",
    "    \n",
    "    dmu = a @ np.array([ei(((dim, dim)),i) for i in range(dim)]) * np.array([np.identity(2)]*dim)\n",
    "    #print(dmu)\n",
    "    dbeta = aux_dbeta * np.array([ei((dim,dim),i) for i in range(dim)])\n",
    "    \n",
    "    dij = np.array([[ei(2, i)[:, np.newaxis] * ei(2,j)[np.newaxis, :] for j in range(2)]for i in range(2)])\n",
    "    \n",
    "    #dij = np.array([[ei(dim,i)[:,np.newaxis,np.newaxis,np.newaxis] * ei(dim,j)[np.newaxis,:,:,:] for j in range(dim)] for i in range(dim)])\n",
    "    #print(dij.shape)\n",
    "    dalpha_cent = a @ dij @ a @ mu0\n",
    "    dalpha_cent = dalpha_cent * np.array([[np.identity(dim)]*dim]*dim)\n",
    "    dalpha_bord = dij * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    \n",
    "\n",
    "    dmu = spectral_matrix @ dmu @ np.conj(spectral_matrix.T)\n",
    "    dalpha = (spectral_matrix @ dalpha_bord @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dalpha_bord), axes=(0, 1, 3, 2)) @ np.conj(spectral_matrix.T))\n",
    "    dalpha += spectral_matrix @ dalpha_cent @ np.conj(spectral_matrix.T)\n",
    "    dbeta = (spectral_matrix @ dbeta @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dbeta), axes=(0, 2, 1)) @ np.conj(spectral_matrix.T))\n",
    "    dnoise = np.identity(dim)\n",
    "    \n",
    "    aux_det = f_inv.T\n",
    "    \n",
    "    aux_trace_mu = (aux_det.T) @ dmu @ (aux_det.T)\n",
    "    aux_trace_alpha = (aux_det.T) @ dalpha @ (aux_det.T)\n",
    "    aux_trace_beta = (aux_det.T) @ dbeta @ (aux_det.T)\n",
    "    aux_trace_noise = (aux_det.T) @ dnoise @ (aux_det.T)\n",
    "\n",
    "\n",
    "    dmu = np.sum(aux_det * dmu, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_mu, axis=tuple(range(1,dim+1)))\n",
    "    dalpha = np.sum(aux_det * dalpha, axis=(2,3)) - np.sum((periodogramw.T) * aux_trace_alpha, axis=(2,3))\n",
    "    dbeta = np.sum(aux_det * dbeta, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_beta, axis=tuple(range(1,dim+1)))\n",
    "    dnoise = np.sum(aux_det * dnoise) - np.sum((periodogramw.T) * aux_trace_noise)\n",
    "    #print(dnoise)\n",
    "    grad_final = np.concatenate((dmu.real.ravel(), dalpha.real.ravel(), dbeta.real.ravel(), np.array([dnoise.real])))\n",
    "\n",
    "    return np.concatenate((np.array([ll.real]), grad_final))\n",
    "\n",
    "# Grad of loglikelihood\n",
    "def grad_ll(theta, periodogram, K, max_time):\n",
    "    \n",
    "    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "    theta_mid = theta[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "\n",
    "    ll = np.sum([grad_completw(theta_aux, j/max_time, periodogram[j-1]) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    \n",
    "    return (ll[0], ll[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8e573c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malpha\u001b[49m[alpha \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "alpha[alpha > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18747015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_completw_mask(theta, w, periodogramw, mask): #better version\n",
    "    mu0, alpha0, beta0, noise0 = theta\n",
    "    \n",
    "    dim = mu0.shape[0]\n",
    "    a = inv(np.identity(dim) - alpha0)\n",
    "    \n",
    "    mean_matrix = np.identity(dim) * (a @ mu0)\n",
    "    \n",
    "    fourier_matrix = alpha0 * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    \n",
    "    f_theta_unnoised = (spectral_matrix) @ mean_matrix @ np.conj(spectral_matrix.T)\n",
    "    f_theta = f_theta_unnoised + noise0 * np.identity(dim)\n",
    "    f_inv = inv(f_theta)\n",
    "    \n",
    "    ll = np.log(det(f_theta)) + np.trace(f_inv @ periodogramw)\n",
    "    \n",
    "    dmu = np.zeros((dim,dim,dim), dtype=np.complex128)\n",
    "    dalpha = np.zeros((dim, dim, dim, dim), dtype=np.complex128)\n",
    "    dbeta = np.zeros((dim, dim, dim), dtype=np.complex128)\n",
    "    aux_dbeta = alpha0 * (2j * np.pi * w) * np.repeat(1/(beta0 +  2j * np.pi * w)**2, dim, axis=1)\n",
    "    \n",
    "    dmu = a @ np.array([ei(((dim, dim)),i) for i in range(dim)]) * np.array([np.identity(2)]*dim)\n",
    "    dbeta = aux_dbeta * mask * np.array([ei((dim,dim),i) for i in range(dim)])\n",
    "    #print(aux_dbeta.shape)\n",
    "    \n",
    "    dij = mask * np.array([[ei(2, i)[:, np.newaxis] * ei(2,j)[np.newaxis, :] for j in range(2)]for i in range(2)])\n",
    "    \n",
    "    dalpha_cent = a @ dij @ a @ mu0\n",
    "    dalpha_cent = dalpha_cent * np.array([[np.identity(dim)]*dim]*dim)\n",
    "    dalpha_bord = dij * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    \n",
    "\n",
    "    dmu = spectral_matrix @ dmu @ np.conj(spectral_matrix.T)\n",
    "    dalpha = (spectral_matrix @ dalpha_bord @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dalpha_bord), axes=(0, 1, 3, 2)) @ np.conj(spectral_matrix.T))\n",
    "    dalpha += spectral_matrix @ dalpha_cent @ np.conj(spectral_matrix.T)\n",
    "    dbeta = (spectral_matrix @ dbeta @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dbeta), axes=(0, 2, 1)) @ np.conj(spectral_matrix.T))\n",
    "    dnoise = np.identity(dim)\n",
    "    \n",
    "    aux_det = f_inv.T\n",
    "    \n",
    "    aux_trace_mu = (aux_det.T) @ dmu @ (aux_det.T)\n",
    "    aux_trace_alpha = (aux_det.T) @ dalpha @ (aux_det.T)\n",
    "    aux_trace_beta = (aux_det.T) @ dbeta @ (aux_det.T)\n",
    "    aux_trace_noise = (aux_det.T) @ dnoise @ (aux_det.T)\n",
    "\n",
    "\n",
    "    dmu = np.sum(aux_det * dmu, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_mu, axis=tuple(range(1,dim+1)))\n",
    "    dalpha = np.sum(aux_det * dalpha, axis=(2,3)) - np.sum((periodogramw.T) * aux_trace_alpha, axis=(2,3))\n",
    "    dbeta = np.sum(aux_det * dbeta, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_beta, axis=tuple(range(1,dim+1)))\n",
    "    dnoise = np.sum(aux_det * dnoise) - np.sum((periodogramw.T) * aux_trace_noise)\n",
    "    #print(dnoise)\n",
    "    grad_final = np.concatenate((dmu.real.ravel(), dalpha.real.ravel(), dbeta.real.ravel(), np.array([dnoise.real])))\n",
    "\n",
    "    return np.concatenate((np.array([ll.real]), grad_final))\n",
    "\n",
    "# Grad of loglikelihood\n",
    "def grad_ll_mask(theta, periodogram, K, max_time, mask=None):\n",
    "    \n",
    "    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.ones((dim, dim))\n",
    "    #print(mask.any(axis=1))\n",
    "    theta_mid = theta[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "    #print(theta_aux)\n",
    "    \n",
    "    ll = np.sum([grad_completw_mask(theta_aux, j/max_time, periodogram[j-1], mask) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    \n",
    "    return (ll[0], ll[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01714c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(11.089347285846328),\n",
       " array([0.8717034 , 0.49311095, 0.        , 0.        , 0.79385799,\n",
       "        0.        , 0.        , 0.01328282, 0.81668877]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_ll_mask(theta+0.1, periodogram, K, max_time, mask=(alpha > 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "334b7dab-e1da-4915-91fd-2e8681d9d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "init_a = np.random.uniform(0, 3, dim * 2 + 1)\n",
    "\n",
    "a = np.random.uniform(0, 3, (dim, dim))\n",
    "radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "init_alpha = a * div / (radius)\n",
    "\n",
    "init = np.concatenate((init_a[0:2].ravel(), init_alpha.ravel(), init_a[2:].ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "405f213c-3009-4ee0-95f3-c6501c9818e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.54534609, 1.97633852, 0.04209392, 0.20535204, 0.74659373,\n",
       "       0.49959415, 0.07473206, 1.61349788, 1.67988108])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9886433e-4b3a-4751-aeb8-689a0e579db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1e-16, None), (1e-16, None), (1e-16, 0.9999999999999999), (1e-16, None), (1e-16, None), (1e-16, 0.9999999999999999), (1e-16, None), (1e-16, None), (1e-16, None)]\n"
     ]
    }
   ],
   "source": [
    "bounds = [(1e-16, None)] * dim\n",
    "bounds += ([(1e-16, 1 - 1e-16)] + [(1e-16, None)] * dim) * (dim-1) + [(1e-16, 1 - 1e-16)]\n",
    "bounds += [(1e-16, None)] * (dim+1)\n",
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2913a7b2-b092-4a73-8d87-ecd7d9469635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.86296205e-01 9.57605691e-01 3.57170027e-02 9.26261857e-02\n",
      " 5.38605235e-01 1.00000000e-16 2.67041921e-01 1.07739052e+00\n",
      " 5.84399804e-01] \n",
      " 544.3696162700653\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res = minimize(grad_ll_mask,\n",
    "               init, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time),\n",
    "               bounds=bounds, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e9e19ef4-512d-4a52-8a88-725845ed167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.86294997e-01 9.57604662e-01 3.57169926e-02 9.26265171e-02\n",
      " 5.38605952e-01 1.00000000e-16 2.67042016e-01 1.07738951e+00\n",
      " 5.84400674e-01] \n",
      " 362.37053203582764\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "resinit = minimize(grad_ll_mask,\n",
    "               init, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time),\n",
    "               bounds=bounds, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(resinit.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea246dc3-0948-435f-961f-9c62b8e56d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = alpha > 0.0\n",
    "start_time = time.time()\n",
    "res2 = minimize(grad_ll_mask,\n",
    "               init, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time, mask),\n",
    "               bounds=bounds, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res2.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5491d420-4dfd-417b-a86b-de7823d090c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-16 1.13538936e-01 2.54651594e-01 7.15576553e-01\n",
      " 1.97148632e-01 4.23419913e-01 1.02219744e-01 3.77322717e+01\n",
      " 1.22842636e+00] \n",
      " 312.26437401771545\n"
     ]
    }
   ],
   "source": [
    "mask = alpha > 0.0\n",
    "start_time = time.time()\n",
    "res2init = minimize(grad_ll_mask,\n",
    "               init, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time, mask),\n",
    "               bounds=bounds, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res2init.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b9487d9-bb79-4162-8d18-7afed6eae18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49750199, 1.9644999 , 0.08614344, 0.31257596, 1.04177331,\n",
       "       0.16691139, 2.58829135, 0.79054765, 2.55276595])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f80f1674-1a58-4389-be35-ff83186cfa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 1. , 0.5, 1.3, 0.5]),\n",
       " array([0.49750199, 1.9644999 , 1.04177331, 0.79054765, 2.55276595]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[param_mask], init[param_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cfe21f2-b78e-4205-bd5a-53e6dce93c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38234393 0.44156434 1.1756303  1.1414391  1.10575127] \n",
      " 79.28682208061218\n"
     ]
    }
   ],
   "source": [
    "param_mask = np.concatenate(([True]*dim, mask.ravel(), mask.any(axis=1), [True]))\n",
    "\n",
    "bounds_short = [(1e-16, None), (1e-16, None), (1e-16, None), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "init_short = init[param_mask]\n",
    "\n",
    "start_time = time.time()\n",
    "res3 = minimize(spectral_multivariate_noised_ll_single,\n",
    "               init_short, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=None,\n",
    "               args=(periodogram, K, max_time),\n",
    "               bounds=bounds_short, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res3.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c16f69b-dd45-4a70-99e9-50a71ab7555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.43915891e+00 1.45061776e+00 1.14650560e-01 4.35176926e-02\n",
      " 4.71615560e-01 1.09437173e-01 2.09588009e+00 9.62230634e-01\n",
      " 1.00000000e-16] \n",
      " 857.0592751502991\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res3init = minimize(spectral_multivariate_noised_ll,\n",
    "               init, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=None,\n",
    "               args=(periodogram, K, max_time),\n",
    "               bounds=bounds, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res3init.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df72f7c0-06c5-4727-9a11-5c7b44129c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_grad_ll_mask(theta, periodogram, K, max_time, mask=None, dim=2):\n",
    "        \n",
    "    if mask is None:\n",
    "        mask = np.ones((dim, dim))\n",
    "\n",
    "    list_aux = list(theta) \n",
    "    param_mask = np.concatenate(([True]*dim, mask.ravel(), mask.any(axis=1), [True]))\n",
    "    #print(param_mask, list_aux)\n",
    "    #print(mask.any(axis=1))\n",
    "    theta_mask = np.zeros((dim * (2+dim) + 1))\n",
    "    theta_mask[-dim-1:-1] += 1\n",
    "    n=0\n",
    "    #print(theta_mask)\n",
    "    for i in range(param_mask.shape[0]):\n",
    "        if param_mask[i]:\n",
    "            theta_mask[i] = list_aux[n]\n",
    "            n += 1\n",
    "    #print(theta_mask)\n",
    "    \n",
    "    theta_mid = theta_mask[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta_mask[-1])\n",
    "    #print(theta_aux)\n",
    "\n",
    "    ll = np.sum([grad_completw_mask(theta_aux, j/max_time, periodogram[j-1], mask) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    \n",
    "    return (ll[0], ll[1:][param_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f11c125-61d5-42c3-8ad6-cb72c4972580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(10.720227138364516),\n",
       " array([ 0.01210012, -0.01717267, -0.00449357,  0.00244323, -0.0055583 ]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_grad_ll_mask(theta[param_mask], periodogram, K, max_time, mask, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d3f41e6-e2ca-48e6-8c7a-44812bd23051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1e-16, None],\n",
       "       [1e-16, None],\n",
       "       [1e-16, 0.9999999999999999],\n",
       "       [1e-16, None],\n",
       "       [1e-16, None],\n",
       "       [1e-16, 0.9999999999999999],\n",
       "       [1e-16, None],\n",
       "       [1e-16, None],\n",
       "       [1e-16, None]], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee3cb415-b538-4fe4-ade4-9d5f8c9083ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38233808 0.44156031 1.17564356 1.14144356 1.10575729] \n",
      " 111.0064001083374\n"
     ]
    }
   ],
   "source": [
    "param_mask = np.concatenate(([True]*dim, mask.ravel(), mask.any(axis=1), [True]))\n",
    "\n",
    "bounds_short = np.array(bounds)[param_mask]\n",
    "\n",
    "init_short = init[param_mask]\n",
    "\n",
    "start_time = time.time()\n",
    "res4 = minimize(small_grad_ll_mask,\n",
    "               init_short, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time, mask, dim),\n",
    "               bounds=bounds_short, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res4.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2eff48a4-fccd-4a11-ab00-1b52ab7f439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38233737 0.44156011 1.17564453 1.14144532 1.10575799] \n",
      " 108.37094283103943\n"
     ]
    }
   ],
   "source": [
    "param_mask = np.concatenate(([True]*dim, mask.ravel(), mask.any(axis=1), [True]))\n",
    "\n",
    "bounds_short = np.array(bounds)[param_mask]\n",
    "\n",
    "init_short = init[param_mask]\n",
    "\n",
    "start_time = time.time()\n",
    "res4init = minimize(small_grad_ll_mask,\n",
    "               init_short, tol=1e-16,\n",
    "               method=\"L-BFGS-B\", jac=True,\n",
    "               args=(periodogram, K, max_time, mask, dim),\n",
    "               bounds=bounds_short, options={\"disp\":False})\n",
    "end_time = time.time()\n",
    "print(res4init.x, \"\\n\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f43f0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 1. , 0. , 0. , 0.5, 0. , 1. , 1.3, 0.5]),\n",
       " array([[False, False],\n",
       "        [ True, False]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, alpha > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b9d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b16d5dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(alpha > 0.0).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68a46589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  0.5 1.3 0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01209877, -0.01717382, -0.00449596,  0.00244427, -0.00555822])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "theta_red = np.concatenate((mu.ravel(), alpha[alpha>0.0].ravel(), beta[(alpha > 0.0).any(axis=1)].ravel(), np.array([noise])))\n",
    "print(theta_red)\n",
    "approx_fprime(theta_red, spectral_multivariate_noised_ll_single, 1e-9, periodogram, K, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b1d6eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9601376683649496\n"
     ]
    }
   ],
   "source": [
    "dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "theta_mid = theta[:-1]\n",
    "theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "a = grad_completw(theta_aux, 1/max_time, periodogram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7ecc578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.96013767e+00, -5.30689833e-01, -3.19529570e-02, -1.56010638e+00,\n",
       "       -1.43922257e+00, -1.09018651e-01, -1.80452255e-01,  0.00000000e+00,\n",
       "       -1.43718372e-03, -5.16121657e-01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17d5c729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.96013767e+00, -5.30689833e-01, -3.19529570e-02, -1.56010638e+00,\n",
       "       -1.43922257e+00, -1.09018651e-01, -1.80452255e-01,  0.00000000e+00,\n",
       "       -1.43718372e-03, -5.16121657e-01])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((a[0], a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "835f3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad of loglikelihood\n",
    "def grad_ll(theta, periodogram, K, max_time):\n",
    "    \n",
    "    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "    theta_mid = theta[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "\n",
    "    ll = np.sum([grad_completw(theta_aux, j/max_time, periodogram[j-1]) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    \n",
    "    return (ll[0], ll[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a35b4d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6856\n",
      "0.08586525917053223\n"
     ]
    }
   ],
   "source": [
    "max_time = 2000\n",
    "np.random.seed(2)#2000, 18, nlog n ? 5000, 389, 3839\n",
    "hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "hp.simulate()\n",
    "hp_times = hp.timestamps\n",
    "\n",
    "pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "pp.simulate()\n",
    "pp_times = pp.timestamps\n",
    "\n",
    "idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "K = int(parasited_times.shape[0])\n",
    "#K = int(K * np.log(K))\n",
    "print(K)\n",
    "start_time = time.time()\n",
    "periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bcfe74bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.206073999404907\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "periodogram = [multivariate_periodogram_good(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eaeb93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4716629981994629 \n",
      " (np.float64(10.720227138364441), array([ 0.01210012, -0.01717267, -0.00261532,  0.0267688 , -0.00449357,\n",
      "       -0.05538602,  0.        ,  0.00244323, -0.0055583 ]))\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "a = grad_ll(theta, periodogram, K, max_time)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time, \"\\n\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26846602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(11.399633019759083)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_multivariate_noised_ll(theta, periodogram, K, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "285860be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01210054, -0.01717382, -0.0026148 ,  0.0267697 , -0.00449418,\n",
       "       -0.05538681,  0.        ,  0.00244249, -0.00555822])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "approx_fprime(theta, spectral_multivariate_noised_ll, 1e-9, periodogram, K, max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dcb809-1e3b-4998-b0c7-351b7e9d3bcf",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8f5b8",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ba779ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral radius: 0.0\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([[1.0],\n",
    "               [1.0]])\n",
    "\n",
    "alpha = np.array([[0.0, 0.0],\n",
    "                  [0.5, 0.0]])\n",
    "\n",
    "beta = np.array([[1.0],\n",
    "                 [1.3]])\n",
    "\n",
    "noise = 0.5\n",
    "\n",
    "theta = np.concatenate((mu.ravel(), alpha.ravel(), beta.ravel(), np.array([noise])))\n",
    "theta\n",
    "\n",
    "print(\"Spectral radius:\", np.max(np.abs(np.linalg.eig(alpha)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13655143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----[[8.04391699e-01 7.07924065e-01 7.70970933e-01 1.16643960e+00\n",
      "  6.60687520e-01]\n",
      " [1.46170525e+00 1.72482212e+00 2.35983817e-01 1.97789173e+00\n",
      "  1.00000000e-16]\n",
      " [3.91540886e-01 5.27518394e-01 1.09868181e+00 1.22473443e+00\n",
      "  1.05261324e+00]\n",
      " [8.68772653e-01 1.00339625e+00 4.77232705e-01 2.23202514e+00\n",
      "  5.98577835e-01]\n",
      " [1.50297040e+00 1.49331815e+00 3.20984519e-01 1.58413529e+00\n",
      "  1.00000000e-16]]\n",
      "[1.00587618 1.0913958  0.58077076 1.63704524 0.46237572]\n"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool, cpu_count\n",
    "# Reduced model estimation (parallel) Good\n",
    "\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, None), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.uniform(0, 3, 5)\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll_single,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations_max = np.array(p.map(job, range(repetitions)))\n",
    "print(estimations_max)\n",
    "print(estimations_max.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b0011f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[1.41159461e+00 1.29973177e+00 1.00000000e-16 2.68702085e-02\n",
      "  4.02243830e-01 5.01557528e-02 2.95385583e+00 1.22506070e+00\n",
      "  1.00000000e-16]\n",
      " [1.40050260e+00 1.72473962e+00 1.00000000e-16 2.95677902e-02\n",
      "  2.36041570e-01 1.00000000e-16 3.61299155e-01 1.97690699e+00\n",
      "  1.00000000e-16]\n",
      " [1.33950023e+00 1.46226425e+00 6.75674759e-02 1.00000000e-16\n",
      "  2.75144591e-01 7.60037305e-02 4.30800960e+00 1.32612993e+00\n",
      "  1.00000000e-16]\n",
      " [8.69599370e-01 1.00414837e+00 1.00000000e-16 1.00000000e-16\n",
      "  4.76795689e-01 4.22529772e-05 8.45508432e-01 2.23188091e+00\n",
      "  5.97752887e-01]\n",
      " [1.46935398e+00 1.48755953e+00 3.28564845e-03 1.08483357e-02\n",
      "  3.22241590e-01 1.00000000e-16 1.32052422e+01 1.57679922e+00\n",
      "  6.23558479e-03]]\n",
      "[1.29811016 1.39568871 0.01417062 0.01345727 0.34249345 0.02524035\n",
      " 4.33478304 1.66735555 0.12079769]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) good\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    \n",
    "    init_a = np.random.chisquare(3, dim*2 + 1)\n",
    "\n",
    "    a = np.random.chisquare(3, (dim, dim))\n",
    "    radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    init_alpha = a * div / (radius)\n",
    "\n",
    "    init = np.concatenate((init_a[0:2].ravel(), init_alpha.ravel(), init_a[2:].ravel()))\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    res = minimize(grad_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=True,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "start_time = time.time()\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc38810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[9.45959446e-01 1.79370733e+00 1.00000000e-16 2.60740057e-01\n",
      "  2.89011036e-02 7.49201763e-02 1.22102990e+00 3.26424047e+00\n",
      "  1.00000000e-16]\n",
      " [4.41349857e-01 1.40067929e+00 1.00000000e-16 2.48707815e-01\n",
      "  1.00000000e-16 1.00000000e-16 1.98396551e+00 5.35961373e-01\n",
      "  6.70504703e-01]\n",
      " [7.69808394e-01 1.43343025e+00 7.87493824e-02 1.54809560e-01\n",
      "  1.00000000e-16 1.53710342e-01 3.11169456e+00 8.27501565e-01\n",
      "  3.17606196e-01]\n",
      " [1.09144610e+00 1.87479322e+00 1.00000000e-16 1.85547704e-01\n",
      "  1.00000000e-16 7.06698514e-02 2.54439117e+00 1.18621304e+00\n",
      "  1.00000000e-16]\n",
      " [1.04514436e+00 1.79623517e+00 1.00000000e-16 2.30808676e-01\n",
      "  1.00000000e-16 9.12814046e-02 1.68943754e+00 3.72968375e-01\n",
      "  1.00000000e-16]]\n",
      "[0.85874163 1.65976905 0.01574988 0.21612276 0.00578022 0.07811635\n",
      " 2.11010374 1.23737696 0.19762218]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) bad\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.rand(9)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram_bad(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f539fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------------------|\n",
      "|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------|\n",
      " Done\n"
     ]
    }
   ],
   "source": [
    "# Without noise model estimation (parallel)\n",
    "max_time = 3000\n",
    "repetitions = 50\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), \n",
    "          (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    \n",
    "    #init_a = np.random.uniform(0,3, dim*2)\n",
    "    #a = np.random.uniform(0,3, (dim,dim))\n",
    "    #radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    #div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    #init_alpha = a * div / (radius)\n",
    "    \n",
    "    #init = np.concatenate((init_a[0:dim].ravel(), init_alpha.ravel(), init_a[dim:].ravel()))\n",
    "    init = np.random.rand(8)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(4) as p:\n",
    "    estimations_nonoised_model = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "#print(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d142f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "explanation = \"Estimations for Scenario (Single).\"\n",
    "explanation += \" First is explanation, second is estimations in non-noised model,\"\n",
    "explanation += \" Dimensions (repetitions, parameters).\"\n",
    "explanation\n",
    "toSave = (explanation, estimations_nonoised_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d2bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('estimationsSingleNonNoisedModel2410.pkl', 'wb') as file:\n",
    "    pickle.dump(toSave, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
