{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52db1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import norm, inv, det\n",
    "import time\n",
    "import seaborn as sns\n",
    "from multiprocess import Pool, cpu_count\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b607f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_exponential_hawkes(object):\n",
    "    \"\"\"\n",
    "    Multivariate Hawkes process with exponential kernel. No events nor initial conditions considered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, alpha, beta, max_jumps=None, max_time=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : array_like\n",
    "            Baseline intensity vector. mu.shape[0] must coincide with shapes for alpha and beta.\n",
    "        alpha : array_like\n",
    "            Interaction factors matrix. Must be a square array with alpha.shape[0] coinciding with mu and beta.\n",
    "        beta : array_like\n",
    "            Decay factor matrix. Must be either an array. When corresponding to decay for each process i, it must\n",
    "            be of shape (number_of_process, 1), or a square array. beta.shape[0] must coincide with mu and alpha.\n",
    "        max_jumps : float, optional\n",
    "            Maximal number of jumps. The default is None.\n",
    "        max_time : float, optional\n",
    "            Maximal time horizon. The default is None.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        nb_processes : int\n",
    "            Number of dimensions.\n",
    "        timestamps : list of tuple (float, int)\n",
    "            List of simulated events and their marks.\n",
    "        intensity_jumps : array of float\n",
    "            Array containing all intensities at each jump. It includes the baseline intensities mu.\n",
    "        simulated : bool\n",
    "            Parameter that marks if a process has been already been simulated,\n",
    "            or if its event times have been initialized.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # We must begin by verifying that the process is a point process. In other words, that the number of\n",
    "        # points in any bounded interval is a.s. finite. For this, we have to verify that the spectral radius of\n",
    "        # the matrix alpha/beta (term by term) is <1.\n",
    "\n",
    "        beta_radius = np.copy(beta)\n",
    "        beta_radius[beta_radius == 0] = 1\n",
    "        spectral_radius = np.max(np.abs(np.linalg.eig(np.abs(alpha) / beta_radius)[0]))\n",
    "\n",
    "        if spectral_radius >= 1:\n",
    "            # raise ValueError(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius))\n",
    "            warnings.warn(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius),RuntimeWarning)\n",
    "        self.mu = mu.reshape((alpha.shape[0], 1))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_jumps = max_jumps\n",
    "        self.max_time = max_time\n",
    "\n",
    "        self.nb_processes = self.mu.shape[0]\n",
    "        self.count = np.zeros(self.nb_processes, dtype=int)\n",
    "\n",
    "        self.timestamps = [(0.0, 0)]\n",
    "        self.intensity_jumps = np.copy(mu)\n",
    "\n",
    "        self.simulated = False\n",
    "\n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "        Auxiliary function to check if already simulated and, if not, which simulation to launch.\n",
    "\n",
    "        Simulation follows Ogata's adapted thinning algorithm. Upper bound obtained by the positive-part process.\n",
    "\n",
    "        Works with both self-exciting and self-regulating processes.\n",
    "\n",
    "        To launch simulation either self.max_jumps or self.max_time must be other than None, so the algorithm knows when to stop.\n",
    "        \"\"\"\n",
    "        if not self.simulated:\n",
    "            if self.max_jumps is not None and self.max_time is None:\n",
    "                self.simulate_jumps()\n",
    "            elif self.max_time is not None and self.max_jumps is None:\n",
    "                self.simulate_time()\n",
    "            else:\n",
    "                print(\"Either max_jumps or max_time must be given.\")\n",
    "            self.simulated = True\n",
    "\n",
    "        else:\n",
    "            print(\"Process already simulated\")\n",
    "\n",
    "    def simulate_jumps(self):\n",
    "        \"\"\"\n",
    "        Simulation is done until the maximal number of jumps (self.max_jumps) is attained.\n",
    "        \"\"\"\n",
    "        flag = 0\n",
    "        t = 0\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag < self.max_jumps:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1, np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            if type_event < self.nb_processes:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                flag += 1\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.max_time = self.timestamps[-1][0]\n",
    "        # Important to add the max_time for plotting and being consistent.\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def simulate_time(self):\n",
    "        \"\"\"\n",
    "        Simulation is done for a window [0, T] (T = self.max_time) is attained.\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        flag = t < self.max_time\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1,\n",
    "                                               np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            flag = t < self.max_time\n",
    "            if type_event < self.nb_processes and flag:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def plot_intensity(self, ax=None, plot_N=True, where=10):\n",
    "        \"\"\"\n",
    "        Plot intensity function. If plot_N is True, plots also step functions N^i([0,t]).\n",
    "        The parameter ax allows to plot the intensity function in a previously created plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : array of Axes, optional.\n",
    "            If None, method will generate own figure.\n",
    "            Otherwise, will use given axes. Must be array of shape (2,K) if plot_N = True, or (K,) if plot_N = False\n",
    "        plot_N : bool, optional.\n",
    "            Whether we plot the step function N^i or not.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.simulated:\n",
    "            print(\"Simulate first\")\n",
    "\n",
    "        else:\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            if plot_N:\n",
    "                jumps_plot = [[0] for i in range(self.nb_processes)]\n",
    "                if ax is None:\n",
    "                    fig, ax = plt.subplots(2, self.nb_processes, sharex=True)\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                elif isinstance(ax[0,0], matplotlib.axes.Axes):\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (2, number of processes+1)\"\n",
    "            else:\n",
    "                if ax is None:\n",
    "                    fig, ax1 = plt.subplots(1, self.nb_processes)\n",
    "                elif isinstance(ax, matplotlib.axes.Axes) or isinstance(ax, np.ndarray):\n",
    "                    ax1 = ax\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (number of processes+1,)\"\n",
    "\n",
    "            times = [0, self.timestamps[1][0]]\n",
    "            intensities = np.array([[self.mu[i, 0], self.mu[i, 0]] for i in range(self.nb_processes)])\n",
    "\n",
    "            ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "            step = 100\n",
    "            # print(\"here\", self.timestamps[len(self.timestamps)])\n",
    "\n",
    "            for i in range(1, len(self.timestamps[1:where])):\n",
    "                # On commence par mettre à jour la matrice lambda^{ij}\n",
    "                ij_intensity = np.multiply(ij_intensity,\n",
    "                                           np.exp(-self.beta * (self.timestamps[i][0] - self.timestamps[i - 1][0])))\n",
    "                # On enregistre le saut d'intensité de l'évenement, pour son type.\n",
    "                ij_intensity[:, self.timestamps[i][1]-1] += self.alpha[:, self.timestamps[i][1]-1]\n",
    "\n",
    "                # On définit la fonction à tracer entre T_n et T_{n+1}\n",
    "                func = lambda x: self.mu + np.matmul(\n",
    "                    np.multiply(ij_intensity, np.exp(-self.beta * (x - self.timestamps[i][0]))),\n",
    "                                np.ones((self.nb_processes, 1)))\n",
    "\n",
    "                # On enregistre la division de temps et les sauts\n",
    "                interval_t = np.linspace(self.timestamps[i][0], self.timestamps[i + 1][0], step)\n",
    "                times += interval_t.tolist()\n",
    "\n",
    "                intensities = np.concatenate((intensities, np.array(list(map(func, interval_t))).squeeze().T ), axis=1)\n",
    "                if plot_N:\n",
    "                    jumps_plot[self.timestamps[i][1]-1] += [self.timestamps[i][0] for t in range(2)]\n",
    "\n",
    "            for i in range(self.nb_processes):\n",
    "                ax1[i].plot(times, intensities[i], label=\"Underlying intensity\", c=\"#1f77b4\", linestyle=\"--\")\n",
    "                ax1[i].plot(times, np.maximum(intensities[i], 0), label=\"Conditional intensity\", c='r')\n",
    "                # ax1[i].plot([i for i,j in self.timestamps[:-1]], self.intensity_jumps[i,:], c='k', alpha=0.5)\n",
    "\n",
    "            ax1[0].legend()\n",
    "\n",
    "            if plot_N:\n",
    "                for i in range(self.nb_processes):\n",
    "                    jumps_plot[i] += [times[-1]]\n",
    "                    ax2[i].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"r\", label=\"Process #%s\"%(i+1))\n",
    "                    # ax2[i].set_ylim(ax2[i].get_ylim())\n",
    "                    for j in range(self.nb_processes):\n",
    "                        if j != i:\n",
    "                            ax2[j].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"#1f77b4\", alpha=0.5)\n",
    "\n",
    "                    ax2[i].legend()\n",
    "\n",
    "    def plot_heatmap(self, ax=None):\n",
    "        \"\"\"\n",
    "        This function allows to observe the heatmap where each cell {ij} corresponds to the value {alpha/beta} from that interaction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : .axes.Axes, optional.\n",
    "            If None, method will generate own ax.\n",
    "            Otherwise, will use given ax.\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        else:\n",
    "            ax = ax\n",
    "        beta_heat = np.copy(self.beta)\n",
    "        beta_heat[beta_heat == 0] = 1\n",
    "        heat_matrix = self.alpha/beta_heat\n",
    "\n",
    "        hex_list = ['#FF3333', '#FFFFFF', '#33FF49']\n",
    "\n",
    "        ax = sns.heatmap(heat_matrix, cmap=get_continuous_cmap(hex_list), center=0, ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9954b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finufft\n",
    "def fast_multi_periodogram(K, tList, max_time, precision=1e-9):\n",
    "    \n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    # put K for w=0\n",
    "    aux = np.array([finufft.nufft1d1(2*np.pi*np.array(x)/max_time, np.ones(len(x)) + 0j, n_modes = 2*K+1, isign=-1, eps=1e-9)[K+1:] for x in dimensional_times]) \n",
    "    aux = (aux.T)[:,:, np.newaxis]\n",
    "    aux = (aux @ np.transpose(np.conj(aux), axes=(0,2,1))) / max_time\n",
    "    \n",
    "    return aux\n",
    "\n",
    "def ei(size, index):\n",
    "    e = np.zeros((size))\n",
    "    e[index] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18747015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_completw_mask(theta, w, periodogramw, mask): #better version\n",
    "    mu0, alpha0, beta0, noise0 = theta\n",
    "    \n",
    "    dim = mu0.shape[0]\n",
    "    a = inv(np.identity(dim) - alpha0)\n",
    "    \n",
    "    mean_matrix = np.identity(dim) * (a @ mu0)\n",
    "    \n",
    "    fourier_matrix = alpha0 * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    \n",
    "    f_theta_unnoised = (spectral_matrix) @ mean_matrix @ np.conj(spectral_matrix.T)\n",
    "    f_theta = f_theta_unnoised + noise0 * np.identity(dim)\n",
    "    f_inv = inv(f_theta)\n",
    "    \n",
    "    ll = np.log(det(f_theta)) + np.trace(f_inv @ periodogramw)\n",
    "    \n",
    "    dmu = np.zeros((dim,dim,dim), dtype=np.complex128)\n",
    "    dalpha = np.zeros((dim, dim, dim, dim), dtype=np.complex128)\n",
    "    dbeta = np.zeros((dim, dim, dim), dtype=np.complex128)\n",
    "    aux_dbeta = alpha0 * (2j * np.pi * w) * np.repeat(1/(beta0 +  2j * np.pi * w)**2, dim, axis=1)\n",
    "    \n",
    "    dmu = a @ np.array([ei(((dim, dim)),i) for i in range(dim)]) * np.array([np.identity(2)]*dim)\n",
    "    dbeta = aux_dbeta * np.array([ei((dim,dim),i) for i in range(dim)])\n",
    "    \n",
    "    dij = mask * np.array([[ei(2, i)[:, np.newaxis] * ei(2,j)[np.newaxis, :] for j in range(2)]for i in range(2)])\n",
    "    \n",
    "    dalpha_cent = a @ dij @ a @ mu0\n",
    "    dalpha_cent = dalpha_cent * np.array([[np.identity(dim)]*dim]*dim)\n",
    "    dalpha_bord = dij * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    \n",
    "\n",
    "    dmu = spectral_matrix @ dmu @ np.conj(spectral_matrix.T)\n",
    "    dalpha = (spectral_matrix @ dalpha_bord @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dalpha_bord), axes=(0, 1, 3, 2)) @ np.conj(spectral_matrix.T))\n",
    "    dalpha += spectral_matrix @ dalpha_cent @ np.conj(spectral_matrix.T)\n",
    "    dbeta = (spectral_matrix @ dbeta @ f_theta_unnoised) + (f_theta_unnoised @ np.transpose(np.conj(dbeta), axes=(0, 2, 1)) @ np.conj(spectral_matrix.T))\n",
    "    dnoise = np.identity(dim)\n",
    "    \n",
    "    aux_det = f_inv.T\n",
    "    \n",
    "    aux_trace_mu = (aux_det.T) @ dmu @ (aux_det.T)\n",
    "    aux_trace_alpha = (aux_det.T) @ dalpha @ (aux_det.T)\n",
    "    aux_trace_beta = (aux_det.T) @ dbeta @ (aux_det.T)\n",
    "    aux_trace_noise = (aux_det.T) @ dnoise @ (aux_det.T)\n",
    "\n",
    "\n",
    "    dmu = np.sum(aux_det * dmu, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_mu, axis=tuple(range(1,dim+1)))\n",
    "    dalpha = np.sum(aux_det * dalpha, axis=(2,3)) - np.sum((periodogramw.T) * aux_trace_alpha, axis=(2,3))\n",
    "    dbeta = np.sum(aux_det * dbeta, axis=tuple(range(1,dim+1))) - np.sum((periodogramw.T) * aux_trace_beta, axis=tuple(range(1,dim+1)))\n",
    "    dnoise = np.sum(aux_det * dnoise) - np.sum((periodogramw.T) * aux_trace_noise)\n",
    "    #print(dnoise)\n",
    "    grad_final = np.concatenate((dmu.real.ravel(), dalpha.real.ravel(), dbeta.real.ravel(), np.array([dnoise.real])))\n",
    "\n",
    "    return np.concatenate((np.array([ll.real]), grad_final))\n",
    "\n",
    "# Grad of loglikelihood\n",
    "#def grad_ll_mask(theta, periodogram, K, max_time, mask=None):\n",
    "#    \n",
    "#    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "#    \n",
    "#    if mask is None:\n",
    "#        mask = np.ones((dim, dim))\n",
    "#    print(mask.any(axis=1))\n",
    "#    theta_mid = theta[:-1]\n",
    "#    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "#    print(theta_aux)\n",
    "#    \n",
    "#    ll = np.sum([grad_completw_mask(theta_aux, j/max_time, periodogram[j-1], mask) for j in range(1, K+1)], axis=0)\n",
    "#    ll /= max_time\n",
    "#    \n",
    "#    return (ll[0], ll[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f6eaff-a911-4108-9f2d-b120d74bba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_grad_ll_mask(theta, periodogram, K, max_time, mask=None):\n",
    "\n",
    "    dim = (periodogram[0]).shape[0]\n",
    "        \n",
    "    if mask is not None:\n",
    "        mask_aux = mask\n",
    "        \n",
    "        list_aux = list(theta) \n",
    "        param_mask = np.concatenate(([True]*dim, mask.ravel(), mask.any(axis=1), [True]))\n",
    "        theta_mask = np.zeros((dim * (2+dim) + 1))\n",
    "        theta_mask[-dim-1:-1] = 1\n",
    "    \n",
    "        true_indices = np.where(param_mask)[0]\n",
    "        theta_mask[true_indices] = list_aux[:len(true_indices)]\n",
    "\n",
    "    else:\n",
    "        mask_aux = np.ones((dim, dim))\n",
    "        param_mask = np.array([True] * (dim * (2 + dim) + 1))\n",
    "        theta_mask = theta\n",
    "        \n",
    "    theta_mid = theta_mask[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta_mask[-1])\n",
    "    #print(theta_aux)\n",
    "    \n",
    "    ll = np.sum([grad_completw_mask(theta_aux, j/max_time, periodogram[j-1], mask_aux) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    \n",
    "    return (ll[0], ll[1:][param_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "952babdb-9eec-4b29-a069-15976f32d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_estimator_bfgs(object):\n",
    "    def __init__(self, loss=small_grad_ll_mask, grad=True, initial_guess=\"random\", mask=None, options=None):\n",
    "        self.loss = loss\n",
    "        self.grad = True # By default uses grad version of spectral ll\n",
    "        self.initial_guess = initial_guess\n",
    "        self.mask = mask\n",
    "        \n",
    "        if options is None:\n",
    "            self.options = {'disp': False}\n",
    "        else:\n",
    "            self.options = options\n",
    "\n",
    "    def fit(self, periodogram, max_time):\n",
    "\n",
    "        K = int(periodogram.shape[0])\n",
    "        self.dim = (periodogram[0]).shape[0]\n",
    "\n",
    "        # Bounds\n",
    "        bounds = [(1e-16, None)] * self.dim\n",
    "        bounds += ([(1e-16, 1 - 1e-16)] + [(1e-16, None)] * self.dim) * (self.dim-1) + [(1e-16, 1 - 1e-16)]\n",
    "        bounds += [(1e-16, None)] * (self.dim+1)        \n",
    "\n",
    "        # Initial point\n",
    "        if isinstance(self.initial_guess, str) and self.initial_guess == \"random\":\n",
    "            init_a = np.random.uniform(0, 3, self.dim * 2 + 1)\n",
    "\n",
    "            a = np.random.uniform(0, 3, (self.dim, self.dim))\n",
    "            radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "            div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "            init_alpha = a * div / (radius)\n",
    "        \n",
    "            self.init = np.concatenate((init_a[0:2].ravel(), init_alpha.ravel(), init_a[2:].ravel()))\n",
    "\n",
    "        # Mask of parameters\n",
    "        if self.mask is not None:\n",
    "            param_mask = np.concatenate(([True]*self.dim, self.mask.ravel(), self.mask.any(axis=1), [True]))\n",
    "            bounds = np.array(bounds)[param_mask]\n",
    "            self.init = self.init[param_mask]\n",
    "\n",
    "        #else:\n",
    "        #    param_mask = np.array([True]*(self.dim * (2 + self.dim) + 1))\n",
    "        \n",
    "        # Estimation\n",
    "        self.res = minimize(self.loss,\n",
    "                       self.init, tol=1e-16,\n",
    "                       method=\"L-BFGS-B\", jac=self.grad,\n",
    "                       args=(periodogram, K, max_time, self.mask),\n",
    "                       bounds=bounds, options=self.options)\n",
    "\n",
    "        theta_estim = np.zeros((self.dim * (2+self.dim) + 1))\n",
    "    \n",
    "        true_indices = np.where(param_mask)[0]\n",
    "        theta_estim[true_indices] = self.res.x[:len(true_indices)]\n",
    "\n",
    "        self.mu_estim = theta_estim[0: self.dim].reshape((self.dim, 1))\n",
    "        self.alpha_estim = theta_estim[self.dim: -self.dim-1].reshape((self.dim, self.dim))\n",
    "        self.beta_estim = theta_estim[-self.dim-1:-1].reshape((self.dim, 1))\n",
    "        self.noise_estim = theta_estim[-1]\n",
    "\n",
    "        return self.mu_estim, self.alpha_estim, self.beta_estim, self.noise_estim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8f5b8",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ba779ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral radius: 0.014142135623730952\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([[1.0],\n",
    "               [1.0]])\n",
    "\n",
    "alpha = np.array([[0.0, 0.01],\n",
    "                  [0.02, 0.0]])\n",
    "\n",
    "beta = np.array([[1.0],\n",
    "                 [1.3]])\n",
    "\n",
    "noise = 0.5\n",
    "\n",
    "theta = np.concatenate((mu.ravel(), alpha.ravel(), beta.ravel(), np.array([noise])))\n",
    "theta\n",
    "\n",
    "print(\"Spectral radius:\", np.max(np.abs(np.linalg.eig(alpha)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81fb7b20-1c78-4889-98af-b4f93d1cdaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3102, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "it = 10\n",
    "max_time = 1000\n",
    "\n",
    "np.random.seed(it)\n",
    "hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "hp.simulate()\n",
    "hp_times = hp.timestamps\n",
    "\n",
    "pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "pp.simulate()\n",
    "pp_times = pp.timestamps\n",
    "\n",
    "idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "K = int(parasited_times.shape[0])\n",
    "#K = int(K*np.log(K))\n",
    "\n",
    "periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "print(periodogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfdaa712-e063-4344-b7dd-83aa358e3dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m estim \u001b[38;5;241m=\u001b[39m multivariate_estimator_bfgs()\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mestim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiodogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end_time\u001b[38;5;241m-\u001b[39mstart_time, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sec.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 44\u001b[0m, in \u001b[0;36mmultivariate_estimator_bfgs.fit\u001b[0;34m(self, periodogram, max_time)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit[param_mask]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#    param_mask = np.array([True]*(self.dim * (2 + self.dim) + 1))\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Estimation\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m               \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mperiodogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#self.mu_estim = np.array(self.res.x[0: self.dim])\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#self.alpha_estim = np.array(self.res.x[self.dim: -self.dim]).reshape((self.dim, self.dim))\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#self.beta_estim = np.array(self.res.x[-self.dim:])\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:343\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/Documents/Python Projects/noisy_hawkes_process_revision/venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[36], line 25\u001b[0m, in \u001b[0;36msmall_grad_ll_mask\u001b[0;34m(theta, periodogram, K, max_time, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m theta_aux \u001b[38;5;241m=\u001b[39m (theta_mid[:dim]\u001b[38;5;241m.\u001b[39mreshape((dim, \u001b[38;5;241m1\u001b[39m)), theta_mid[dim:\u001b[38;5;241m-\u001b[39mdim]\u001b[38;5;241m.\u001b[39mreshape((dim, dim)), theta_mid[\u001b[38;5;241m-\u001b[39mdim:]\u001b[38;5;241m.\u001b[39mreshape((dim, \u001b[38;5;241m1\u001b[39m)), theta_mask[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print(theta_aux)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m ll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum([\u001b[43mgrad_completw_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodogram\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_aux\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, K\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     26\u001b[0m ll \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m max_time\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (ll[\u001b[38;5;241m0\u001b[39m], ll[\u001b[38;5;241m1\u001b[39m:][param_mask])\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgrad_completw_mask\u001b[0;34m(theta, w, periodogramw, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m dmu \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ei(((dim, dim)),i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim)]) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39midentity(\u001b[38;5;241m2\u001b[39m)]\u001b[38;5;241m*\u001b[39mdim)\n\u001b[1;32m     24\u001b[0m dbeta \u001b[38;5;241m=\u001b[39m aux_dbeta \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ei((dim,dim),i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim)])\n\u001b[0;32m---> 26\u001b[0m dij \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[ei(\u001b[38;5;241m2\u001b[39m, i)[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m ei(\u001b[38;5;241m2\u001b[39m,j)[np\u001b[38;5;241m.\u001b[39mnewaxis, :] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)]\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)])\n\u001b[1;32m     28\u001b[0m dalpha_cent \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m dij \u001b[38;5;241m@\u001b[39m a \u001b[38;5;241m@\u001b[39m mu0\n\u001b[1;32m     29\u001b[0m dalpha_cent \u001b[38;5;241m=\u001b[39m dalpha_cent \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[np\u001b[38;5;241m.\u001b[39midentity(dim)]\u001b[38;5;241m*\u001b[39mdim]\u001b[38;5;241m*\u001b[39mdim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estim = multivariate_estimator_bfgs()\n",
    "start_time = time.time()\n",
    "res = estim.fit(periodogram, max_time)\n",
    "end_time = time.time()\n",
    "print(\"In: \", end_time-start_time, \" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f495e8-f798-4d8c-aa7d-740953a86315",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18b8c934-20b2-4909-8abc-9d44766be080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:  160.27114534378052  sec.\n"
     ]
    }
   ],
   "source": [
    "mask = np.array([[False, True],\n",
    "                 [True, False]])\n",
    "estim_red = multivariate_estimator_bfgs(mask=mask)\n",
    "start_time = time.time()\n",
    "res_red = estim_red.fit(periodogram, max_time)\n",
    "end_time = time.time()\n",
    "print(\"In: \", end_time-start_time, \" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a59e2cc2-1341-45a5-9425-0738184d3409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 17.131985185334354\n",
       "        x: [ 1.531e+00  1.382e+00  3.512e-01  4.120e-01  1.091e+00\n",
       "             1.534e+00  1.000e-16]\n",
       "      nit: 55\n",
       "      jac: [ 5.150e-10  1.164e-09 -5.642e-10  8.100e-09  4.045e-11\n",
       "             1.396e-09  2.012e-03]\n",
       "     nfev: 91\n",
       "     njev: 91\n",
       " hess_inv: <7x7 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13655143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----[[8.04391699e-01 7.07924065e-01 7.70970933e-01 1.16643960e+00\n",
      "  6.60687520e-01]\n",
      " [1.46170525e+00 1.72482212e+00 2.35983817e-01 1.97789173e+00\n",
      "  1.00000000e-16]\n",
      " [3.91540886e-01 5.27518394e-01 1.09868181e+00 1.22473443e+00\n",
      "  1.05261324e+00]\n",
      " [8.68772653e-01 1.00339625e+00 4.77232705e-01 2.23202514e+00\n",
      "  5.98577835e-01]\n",
      " [1.50297040e+00 1.49331815e+00 3.20984519e-01 1.58413529e+00\n",
      "  1.00000000e-16]]\n",
      "[1.00587618 1.0913958  0.58077076 1.63704524 0.46237572]\n"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool, cpu_count\n",
    "# Reduced model estimation (parallel) Good\n",
    "\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, None), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.uniform(0, 3, 5)\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll_single,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations_max = np.array(p.map(job, range(repetitions)))\n",
    "print(estimations_max)\n",
    "print(estimations_max.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b0011f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[1.41159461e+00 1.29973177e+00 1.00000000e-16 2.68702085e-02\n",
      "  4.02243830e-01 5.01557528e-02 2.95385583e+00 1.22506070e+00\n",
      "  1.00000000e-16]\n",
      " [1.40050260e+00 1.72473962e+00 1.00000000e-16 2.95677902e-02\n",
      "  2.36041570e-01 1.00000000e-16 3.61299155e-01 1.97690699e+00\n",
      "  1.00000000e-16]\n",
      " [1.33950023e+00 1.46226425e+00 6.75674759e-02 1.00000000e-16\n",
      "  2.75144591e-01 7.60037305e-02 4.30800960e+00 1.32612993e+00\n",
      "  1.00000000e-16]\n",
      " [8.69599370e-01 1.00414837e+00 1.00000000e-16 1.00000000e-16\n",
      "  4.76795689e-01 4.22529772e-05 8.45508432e-01 2.23188091e+00\n",
      "  5.97752887e-01]\n",
      " [1.46935398e+00 1.48755953e+00 3.28564845e-03 1.08483357e-02\n",
      "  3.22241590e-01 1.00000000e-16 1.32052422e+01 1.57679922e+00\n",
      "  6.23558479e-03]]\n",
      "[1.29811016 1.39568871 0.01417062 0.01345727 0.34249345 0.02524035\n",
      " 4.33478304 1.66735555 0.12079769]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) good\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    \n",
    "    init_a = np.random.chisquare(3, dim*2 + 1)\n",
    "\n",
    "    a = np.random.chisquare(3, (dim, dim))\n",
    "    radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    init_alpha = a * div / (radius)\n",
    "\n",
    "    init = np.concatenate((init_a[0:2].ravel(), init_alpha.ravel(), init_a[2:].ravel()))\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    res = minimize(grad_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=True,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "start_time = time.time()\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc38810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[9.45959446e-01 1.79370733e+00 1.00000000e-16 2.60740057e-01\n",
      "  2.89011036e-02 7.49201763e-02 1.22102990e+00 3.26424047e+00\n",
      "  1.00000000e-16]\n",
      " [4.41349857e-01 1.40067929e+00 1.00000000e-16 2.48707815e-01\n",
      "  1.00000000e-16 1.00000000e-16 1.98396551e+00 5.35961373e-01\n",
      "  6.70504703e-01]\n",
      " [7.69808394e-01 1.43343025e+00 7.87493824e-02 1.54809560e-01\n",
      "  1.00000000e-16 1.53710342e-01 3.11169456e+00 8.27501565e-01\n",
      "  3.17606196e-01]\n",
      " [1.09144610e+00 1.87479322e+00 1.00000000e-16 1.85547704e-01\n",
      "  1.00000000e-16 7.06698514e-02 2.54439117e+00 1.18621304e+00\n",
      "  1.00000000e-16]\n",
      " [1.04514436e+00 1.79623517e+00 1.00000000e-16 2.30808676e-01\n",
      "  1.00000000e-16 9.12814046e-02 1.68943754e+00 3.72968375e-01\n",
      "  1.00000000e-16]]\n",
      "[0.85874163 1.65976905 0.01574988 0.21612276 0.00578022 0.07811635\n",
      " 2.11010374 1.23737696 0.19762218]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) bad\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.rand(9)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram_bad(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f539fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------------------|\n",
      "|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------|\n",
      " Done\n"
     ]
    }
   ],
   "source": [
    "# Without noise model estimation (parallel)\n",
    "max_time = 3000\n",
    "repetitions = 50\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), \n",
    "          (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    \n",
    "    #init_a = np.random.uniform(0,3, dim*2)\n",
    "    #a = np.random.uniform(0,3, (dim,dim))\n",
    "    #radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    #div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    #init_alpha = a * div / (radius)\n",
    "    \n",
    "    #init = np.concatenate((init_a[0:dim].ravel(), init_alpha.ravel(), init_a[dim:].ravel()))\n",
    "    init = np.random.rand(8)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(4) as p:\n",
    "    estimations_nonoised_model = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "#print(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d142f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "explanation = \"Estimations for Scenario (Single).\"\n",
    "explanation += \" First is explanation, second is estimations in non-noised model,\"\n",
    "explanation += \" Dimensions (repetitions, parameters).\"\n",
    "explanation\n",
    "toSave = (explanation, estimations_nonoised_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d2bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('estimationsSingleNonNoisedModel2410.pkl', 'wb') as file:\n",
    "    pickle.dump(toSave, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
