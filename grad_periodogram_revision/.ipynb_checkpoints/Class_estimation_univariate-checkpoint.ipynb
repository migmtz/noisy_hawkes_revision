{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52db1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import norm, inv, det\n",
    "import time\n",
    "import seaborn as sns\n",
    "from multiprocess import Pool, cpu_count\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b607f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_exponential_hawkes(object):\n",
    "    \"\"\"\n",
    "    Multivariate Hawkes process with exponential kernel. No events nor initial conditions considered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, alpha, beta, max_jumps=None, max_time=None, burn_in=0.0):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : array_like\n",
    "            Baseline intensity vector. mu.shape[0] must coincide with shapes for alpha and beta.\n",
    "        alpha : array_like\n",
    "            Interaction factors matrix. Must be a square array with alpha.shape[0] coinciding with mu and beta.\n",
    "        beta : array_like\n",
    "            Decay factor matrix. Must be either an array. When corresponding to decay for each process i, it must\n",
    "            be of shape (number_of_process, 1), or a square array. beta.shape[0] must coincide with mu and alpha.\n",
    "        max_jumps : float, optional\n",
    "            Maximal number of jumps. The default is None.\n",
    "        max_time : float, optional\n",
    "            Maximal time horizon. The default is None.\n",
    "        burn_in : float, optional\n",
    "            Burn-in period for stationary simulation.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        nb_processes : int\n",
    "            Number of dimensions.\n",
    "        timestamps : list of tuple (float, int)\n",
    "            List of simulated events and their marks.\n",
    "        intensity_jumps : array of float\n",
    "            Array containing all intensities at each jump. It includes the baseline intensities mu.\n",
    "        simulated : bool\n",
    "            Parameter that marks if a process has been already been simulated,\n",
    "            or if its event times have been initialized.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # We must begin by verifying that the process is a point process. In other words, that the number of\n",
    "        # points in any bounded interval is a.s. finite. For this, we have to verify that the spectral radius of\n",
    "        # the matrix alpha/beta (term by term) is <1.\n",
    "\n",
    "        beta_radius = np.copy(beta)\n",
    "        beta_radius[beta_radius == 0] = 1\n",
    "        self.spectral_radius = np.max(np.abs(np.linalg.eig(np.abs(alpha))[0]))\n",
    "\n",
    "        if self.spectral_radius >= 1:\n",
    "            # raise ValueError(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius))\n",
    "            warnings.warn(\"Spectral radius is %s, which may make the process unstable.\" % (self.spectral_radius),RuntimeWarning)\n",
    "        self.mu = mu.reshape((alpha.shape[0], 1))\n",
    "        self.alpha = alpha\n",
    "        if beta.shape[1] != alpha.shape[0]: # Initialisation of beta if constant by process\n",
    "            self.beta = np.repeat(beta, alpha.shape[0], axis=1)\n",
    "        else:\n",
    "            self.beta = beta\n",
    "        self.max_jumps = max_jumps\n",
    "        self.max_time = max_time\n",
    "\n",
    "        self.before_origin_time = 0.0\n",
    "        self.aux_before = 0.0 * self.alpha\n",
    "        self.at_origin_intensity = self.mu\n",
    "\n",
    "        self.burn_in = -np.abs(burn_in)\n",
    "\n",
    "        self.nb_processes = self.mu.shape[0]\n",
    "        self.count = np.zeros(self.nb_processes, dtype=int)\n",
    "\n",
    "        self.timestamps = [(burn_in, 0)]\n",
    "        self.intensity_jumps = np.copy(mu)\n",
    "\n",
    "        self.simulated = False\n",
    "\n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "        Auxiliary function to check if already simulated and, if not, which simulation to launch.\n",
    "\n",
    "        Simulation follows Ogata's adapted thinning algorithm. Upper bound obtained by the positive-part process.\n",
    "\n",
    "        Works with both self-exciting and self-regulating processes.\n",
    "\n",
    "        To launch simulation either self.max_jumps or self.max_time must be other than None, so the algorithm knows when to stop.\n",
    "        \"\"\"\n",
    "        if not self.simulated:\n",
    "            if self.max_jumps is not None and self.max_time is None:\n",
    "                self.simulate_jumps()\n",
    "            elif self.max_time is not None and self.max_jumps is None:\n",
    "                if self.spectral_radius >= 1.0:\n",
    "                    raise ValueError(\"Spectral radius is %s, simulation with max_time may not end. Prefer providing max_jumps.\" % (self.spectral_radius))\n",
    "                self.simulate_time()\n",
    "            else:\n",
    "                print(\"Either max_jumps or max_time must be given.\")\n",
    "            self.simulated = True\n",
    "            #self.complete_times = self.timestamps\n",
    "            self.timestamps = [(0.0, 0)] + [(t, m) for t,m in self.timestamps if t > 0.0]\n",
    "\n",
    "        else:\n",
    "            print(\"Process already simulated\")\n",
    "\n",
    "    def simulate_jumps(self):\n",
    "        \"\"\"\n",
    "        Simulation is done until the maximal number of jumps (self.max_jumps) is attained.\n",
    "        \"\"\"\n",
    "        flag = 0\n",
    "        t = self.burn_in\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag < self.max_jumps:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "            if t > 0.0 > previous_t:\n",
    "                self.before_origin_time = previous_t\n",
    "                self.aux_before = np.multiply(ij_intensity, np.exp(-self.beta * (0 - previous_t)))\n",
    "                self.at_origin_intensity = self.mu + np.sum(self.aux_before, axis=1, keepdims=True)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1, np.concatenate((pos_candidate.squeeze(axis=1), np.array([0.0])))).argmax()\n",
    "            if type_event < self.nb_processes:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event] * self.beta[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event] * self.beta[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                flag += 1\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.max_time = self.timestamps[-1][0]\n",
    "        # Important to add the max_time for plotting and being consistent.\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "        #self.timestamps = [(t,m) for t,m in self.timestamps()]\n",
    "\n",
    "    def simulate_time(self):\n",
    "        \"\"\"\n",
    "        Simulation is done for a window [0, T] (T = self.max_time) is attained.\n",
    "        \"\"\"\n",
    "        t = self.burn_in\n",
    "        flag = t < self.max_time\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "            if t > 0.0 > previous_t:\n",
    "                self.before_origin_time = previous_t\n",
    "                self.aux_before = np.multiply(ij_intensity, np.exp(-self.beta * (0 - previous_t)))\n",
    "                self.at_origin_intensity = self.mu + np.sum(self.aux_before, axis=1, keepdims=True)\n",
    "            #print(\"cand\", t, upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            #print((pos_candidate.squeeze(axis=1), pos_candidate.squeeze(), np.array([0.0])))\n",
    "            type_event = np.random.multinomial(1,\n",
    "                                               np.concatenate((pos_candidate.squeeze(axis=1), np.array([0.0])))).argmax()\n",
    "            flag = t < self.max_time\n",
    "            if type_event < self.nb_processes and flag:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event] * self.beta[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event] * self.beta[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "\n",
    "    def plot_intensity(self, ax=None, plot_N=True, where=10):\n",
    "        \"\"\"\n",
    "        Plot intensity function. If plot_N is True, plots also step functions N^i([0,t]).\n",
    "        The parameter ax allows to plot the intensity function in a previously created plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : array of Axes, optional.\n",
    "            If None, method will generate own figure.\n",
    "            Otherwise, will use given axes. Must be array of shape (2,K) if plot_N = True, or (K,) if plot_N = False\n",
    "        plot_N : bool, optional.\n",
    "            Whether we plot the step function N^i or not.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.simulated:\n",
    "            print(\"Simulate first\")\n",
    "\n",
    "        else:\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            if plot_N:\n",
    "                jumps_plot = [[0] for i in range(self.nb_processes)]\n",
    "                if ax is None:\n",
    "                    fig, ax = plt.subplots(2, self.nb_processes, sharex=True)\n",
    "                elif isinstance(ax[0,0], matplotlib.axes.Axes):\n",
    "                    pass\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (2, number of processes+1)\"\n",
    "                ax1 = ax[0]\n",
    "                ax2 = ax[1]\n",
    "                if self.nb_processes == 1:\n",
    "                    ax1 = [ax1]\n",
    "                    ax2 = [ax2]\n",
    "            else:\n",
    "                if ax is None:\n",
    "                    fig, ax1 = plt.subplots(1, self.nb_processes)\n",
    "                elif isinstance(ax, matplotlib.axes.Axes) or isinstance(ax, np.ndarray):\n",
    "                    ax1 = ax\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (number of processes+1,)\"\n",
    "                if self.nb_processes == 1:\n",
    "                    ax1 = [ax1]\n",
    "\n",
    "\n",
    "            ij_intensity = self.aux_before\n",
    "\n",
    "            step = 100\n",
    "\n",
    "            if self.before_origin_time < 0.0:\n",
    "                func = lambda x: self.mu + np.matmul(\n",
    "                    np.multiply(ij_intensity, np.exp(-self.beta * (x))),\n",
    "                    np.ones((self.nb_processes, 1)))\n",
    "\n",
    "                # On enregistre la division de temps et les sauts\n",
    "                interval_t = np.linspace(0.0, self.timestamps[1][0], step)\n",
    "                times = interval_t.tolist()\n",
    "                intensities = np.array(list(map(func, interval_t))).squeeze(axis=-1).T\n",
    "\n",
    "            else:\n",
    "                times = [0, self.timestamps[1][0]]\n",
    "                intensities = np.array([[self.mu[i, 0], self.mu[i, 0]] for i in range(self.nb_processes)])\n",
    "\n",
    "            # print(\"here\", self.timestamps[len(self.timestamps)])\n",
    "            #print(\"where\",len(self.timestamps[1:where]), where)\n",
    "            for i in range(1, len(self.timestamps[1:where])):\n",
    "                # On commence par mettre à jour la matrice lambda^{ij}\n",
    "                ij_intensity = np.multiply(ij_intensity,\n",
    "                                           np.exp(-self.beta * (self.timestamps[i][0] - self.timestamps[i - 1][0])))\n",
    "                # On enregistre le saut d'intensité de l'évenement, pour son type.\n",
    "                ij_intensity[:, self.timestamps[i][1]-1] += self.alpha[:, self.timestamps[i][1]-1] * self.beta[:, self.timestamps[i][1]-1]\n",
    "\n",
    "                # On définit la fonction à tracer entre T_n et T_{n+1}\n",
    "                func = lambda x: self.mu + np.matmul(\n",
    "                    np.multiply(ij_intensity, np.exp(-self.beta * (x - self.timestamps[i][0]))),\n",
    "                                np.ones((self.nb_processes, 1)))\n",
    "\n",
    "                # On enregistre la division de temps et les sauts\n",
    "                interval_t = np.linspace(self.timestamps[i][0], self.timestamps[i + 1][0], step)\n",
    "                times += interval_t.tolist()\n",
    "                intensities = np.concatenate((intensities, np.array(list(map(func, interval_t))).squeeze(axis=-1).T ), axis=1)\n",
    "                if plot_N:\n",
    "                    jumps_plot[self.timestamps[i][1]-1] += [self.timestamps[i][0] for t in range(2)]\n",
    "\n",
    "            for i in range(self.nb_processes):\n",
    "                ax1[i].plot(times, intensities[i], label=\"Underlying intensity\", c=\"#1f77b4\", linestyle=\"--\")\n",
    "                ax1[i].plot(times, np.maximum(intensities[i], 0), label=\"Conditional intensity\", c='r')\n",
    "                # ax1[i].plot([i for i,j in self.timestamps[:-1]], self.intensity_jumps[i,:], c='k', alpha=0.5)\n",
    "\n",
    "            ax1[0].legend()\n",
    "\n",
    "            if plot_N:\n",
    "                for i in range(self.nb_processes):\n",
    "                    jumps_plot[i] += [times[-1]]\n",
    "                    ax2[i].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"r\", label=\"Process #%s\"%(i+1), zorder=10)\n",
    "                    # ax2[i].set_ylim(ax2[i].get_ylim())\n",
    "                    for j in range(self.nb_processes):\n",
    "                        if j != i:\n",
    "                            ax2[j].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"#1f77b4\", alpha=0.5, zorder=5)\n",
    "\n",
    "                    ax2[i].legend()\n",
    "\n",
    "\n",
    "\n",
    "    def plot_heatmap(self, ax=None):\n",
    "        \"\"\"\n",
    "        This function allows to observe the heatmap where each cell {ij} corresponds to the value {alpha/beta} from that interaction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : .axes.Axes, optional.\n",
    "            If None, method will generate own ax.\n",
    "            Otherwise, will use given ax.\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        else:\n",
    "            ax = ax\n",
    "        beta_heat = np.copy(self.beta)\n",
    "        beta_heat[beta_heat == 0] = 1\n",
    "        heat_matrix = self.alpha\n",
    "\n",
    "        hex_list = ['#FF3333', '#FFFFFF', '#33FF49']\n",
    "\n",
    "        ax = sns.heatmap(heat_matrix, cmap=get_continuous_cmap(hex_list), center=0, ax=ax, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9954b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finufft\n",
    "def fast_multi_periodogram(K, tList, max_time, precision=1e-9):\n",
    "    \n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    # put K for w=0\n",
    "    aux = np.array([finufft.nufft1d1(2*np.pi*np.array(x)/max_time, np.ones(len(x)) + 0j, n_modes = 2*K+1, isign=-1, eps=1e-9)[K+1:] for x in dimensional_times]) \n",
    "    aux = (aux.T)[:,:, np.newaxis]\n",
    "    aux = (aux @ np.transpose(np.conj(aux), axes=(0,2,1))) / max_time\n",
    "    \n",
    "    return aux\n",
    "\n",
    "def ei(size, index):\n",
    "    e = np.zeros((size))\n",
    "    e[index] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18747015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_spectral_w_mask(theta, w, periodogramw, mask): # The mask allows to set values to 0.\n",
    "    mu0, alpha0, beta0, noise0 = theta\n",
    "\n",
    "    dim = mu0.shape[0]\n",
    "    a = inv(np.identity(dim) - alpha0)\n",
    "\n",
    "    mean_matrix = np.identity(dim) * (a @ mu0)\n",
    "\n",
    "    fourier_matrix = alpha0 * beta0 / (beta0 + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "\n",
    "    f_theta_unnoised = (spectral_matrix) @ mean_matrix @ np.conj(spectral_matrix.T)\n",
    "    f_theta = f_theta_unnoised + noise0 * np.identity(dim)\n",
    "    f_inv = inv(f_theta)\n",
    "\n",
    "    ll = np.log(det(f_theta)) + np.trace(f_inv @ periodogramw)\n",
    "\n",
    "    #dmu = np.zeros((dim, dim, dim), dtype=np.complex128)\n",
    "    #dalpha = np.zeros((dim, dim, dim, dim), dtype=np.complex128)\n",
    "    #dbeta = np.zeros((dim, dim, dim), dtype=np.complex128)\n",
    "    aux_dbeta = alpha0 * (2j * np.pi * w) * np.repeat(1 / (beta0 + 2j * np.pi * w) ** 2, dim, axis=1)\n",
    "\n",
    "    dmu = a @ np.array([ei(((dim, dim)), i) for i in range(dim)]) * np.array([np.identity(dim)] * dim)\n",
    "    dbeta = aux_dbeta * np.array([ei((dim, dim), i) for i in range(dim)])\n",
    "\n",
    "    dij = mask * np.array([[ei(dim, i)[:, np.newaxis] * ei(dim, j)[np.newaxis, :] for j in range(dim)] for i in range(dim)])\n",
    "    dalpha_cent = a @ dij @ a @ mu0\n",
    "    dalpha_cent = dalpha_cent * np.array([[np.identity(dim)] * dim] * dim)\n",
    "    dalpha_bord = dij * beta0 / (beta0 + 2j * np.pi * w)\n",
    "\n",
    "    dmu = spectral_matrix @ dmu @ np.conj(spectral_matrix.T)\n",
    "    dalpha = (spectral_matrix @ dalpha_bord @ f_theta_unnoised) + (\n",
    "                f_theta_unnoised @ np.transpose(np.conj(dalpha_bord), axes=(0, 1, 3, 2)) @ np.conj(spectral_matrix.T))\n",
    "    dalpha += spectral_matrix @ dalpha_cent @ np.conj(spectral_matrix.T)\n",
    "    dbeta = (spectral_matrix @ dbeta @ f_theta_unnoised) + (\n",
    "                f_theta_unnoised @ np.transpose(np.conj(dbeta), axes=(0, 2, 1)) @ np.conj(spectral_matrix.T))\n",
    "    dnoise = np.identity(dim)\n",
    "    aux_det = f_inv.T\n",
    "\n",
    "    aux_trace_mu = (aux_det.T) @ dmu @ (aux_det.T)\n",
    "    aux_trace_alpha = (aux_det.T) @ dalpha @ (aux_det.T)\n",
    "    aux_trace_beta = (aux_det.T) @ dbeta @ (aux_det.T)\n",
    "    aux_trace_noise = (aux_det.T) @ dnoise @ (aux_det.T)\n",
    "\n",
    "    dmu = np.sum(aux_det * dmu, axis=(1,2)) - np.sum((periodogramw.T) * aux_trace_mu,\n",
    "                                                                        axis=(1,2))\n",
    "    dalpha = np.sum(aux_det * dalpha, axis=(2, 3)) - np.sum((periodogramw.T) * aux_trace_alpha, axis=(2, 3))\n",
    "    dbeta = np.sum(aux_det * dbeta, axis=(1,2)) - np.sum((periodogramw.T) * aux_trace_beta,\n",
    "                                                                            axis=(1,2))\n",
    "    dnoise = np.sum(aux_det * dnoise) - np.sum((periodogramw.T) * aux_trace_noise)\n",
    "\n",
    "    #print(alpha0, dalpha)\n",
    "\n",
    "    grad_final = np.concatenate((dmu.real.ravel(), dalpha.real.ravel(), dbeta.real.ravel(), np.array([dnoise.real])))\n",
    "\n",
    "    return np.concatenate((np.array([ll.real]), grad_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd88b95-94ff-4abc-bcd8-fda94d8a6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_dalpha(mu, alpha, beta, noise, w, periodogramw):\n",
    "\n",
    "    f = (mu/((1-alpha))) * (1 + ((beta**2) * alpha * (2-alpha))/((beta * (1-alpha))**2 + (2 * np.pi * w)**2)) + noise\n",
    "    \n",
    "    res = (mu/((1-alpha)**2)) * (1 + ((beta**2) * alpha * (2-alpha))/((beta * (1-alpha))**2 + (2 * np.pi * w)**2))\n",
    "    res += 2 * mu * (beta**2) * ((beta)**2 + (2 * np.pi * w)**2) / (((beta * (1-alpha))**2 + (2 * np.pi * w)**2)**2)\n",
    "\n",
    "    res = res / f - periodogramw * res / (f**2)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f6eaff-a911-4108-9f2d-b120d74bba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_grad_ll_mask(theta, periodogram, K, max_time, fixed_parameter):\n",
    "\n",
    "    # Fixed parameter must be tuple (index, fixed value)\n",
    "    dim = (periodogram[0]).shape[0]\n",
    "\n",
    "    idx, value_parameter = fixed_parameter\n",
    "        \n",
    "    theta_mid = value_parameter * np.ones((4,))\n",
    "    indices = [i!=idx for i in range(4)]\n",
    "    theta_mid[indices] = theta\n",
    "        \n",
    "    #print(theta_aux)\n",
    "\n",
    "    theta_aux = tuple((np.array([[i]]) for i in theta_mid))\n",
    "    \n",
    "    ll = np.sum([grad_spectral_w_mask(theta_aux, j/max_time, periodogram[j-1], np.array([[1.0]])) for j in range(1, K+1)], axis=0)\n",
    "    ll /= max_time\n",
    "    print(\"here\",theta, ll[1:][indices])\n",
    "    \n",
    "    return (ll[0], ll[1:][indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952babdb-9eec-4b29-a069-15976f32d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class univariate_estimator_bfgs(object):\n",
    "    def __init__(self, fixed_parameter, loss=uni_grad_ll_mask, grad=True, initial_guess=\"random\", options=None):\n",
    "        self.fixed_parameter = fixed_parameter\n",
    "        self.loss = loss\n",
    "        self.grad = True # By default uses grad version of spectral ll\n",
    "        self.initial_guess = initial_guess\n",
    "        \n",
    "        if options is None:\n",
    "            self.options = {'disp': False}#,\"maxls\":40}\n",
    "        else:\n",
    "            self.options = options\n",
    "\n",
    "    def fit(self, periodogram, max_time):\n",
    "\n",
    "        np.random.seed(0)\n",
    "\n",
    "        K = int(periodogram.shape[0])\n",
    "        self.dim = (periodogram[0]).shape[0]\n",
    "\n",
    "        # Bounds\n",
    "        bounds = [(1e-16, None), (1e-16, 1 - 1e-16), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "        # Initial point\n",
    "        if isinstance(self.initial_guess, str) and self.initial_guess == \"random\":\n",
    "            init_a = np.random.uniform(0, 3, 3)\n",
    "            init_alpha = np.random.uniform(0, 1, (self.dim, self.dim))\n",
    "        \n",
    "            self.init = np.concatenate((init_a[0].ravel(), init_alpha.ravel(), init_a[1:].ravel()))\n",
    "\n",
    "        # Mask of non-fixed parameters\n",
    "        indices = [i!=self.fixed_parameter[0] for i in range(4)]\n",
    "        print(indices)\n",
    "        bounds = np.array(bounds)[indices]\n",
    "        self.init = self.init[indices]\n",
    "\n",
    "        #else:\n",
    "        #    param_mask = np.array([True]*(self.dim * (2 + self.dim) + 1))\n",
    "        print(self.init)\n",
    "        # Estimation\n",
    "        self.res = minimize(self.loss,\n",
    "                       self.init, tol=1e-6,\n",
    "                       method=\"L-BFGS-B\", jac=self.grad,\n",
    "                       args=(periodogram, K, max_time, self.fixed_parameter),\n",
    "                       bounds=bounds, options=self.options)\n",
    "\n",
    "        #theta_estim = np.zeros((self.dim * (2+self.dim) + 1))\n",
    "    \n",
    "        #true_indices = np.where(param_mask)[0]\n",
    "        #theta_estim[true_indices] = self.res.x[:len(true_indices)]\n",
    "\n",
    "        #self.mu_estim = theta_estim[0: self.dim].reshape((self.dim, 1))\n",
    "        #self.alpha_estim = theta_estim[self.dim: -self.dim-1].reshape((self.dim, self.dim))\n",
    "        #self.beta_estim = theta_estim[-self.dim-1:-1].reshape((self.dim, 1))\n",
    "        #self.noise_estim = theta_estim[-1]\n",
    "\n",
    "        #return self.mu_estim, self.alpha_estim, self.beta_estim, self.noise_estim\n",
    "        return self.res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8f5b8",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba779ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral radius: 0.5\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([[1.0]])\n",
    "\n",
    "alpha = np.array([[0.5]])\n",
    "\n",
    "beta = np.array([[1.0]])\n",
    "\n",
    "noise = 0.5\n",
    "\n",
    "theta = np.concatenate((mu.ravel(), alpha.ravel(), beta.ravel(), np.array([noise])))\n",
    "theta\n",
    "\n",
    "print(\"Spectral radius:\", np.max(np.abs(np.linalg.eig(alpha)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81fb7b20-1c78-4889-98af-b4f93d1cdaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In : 0.0682680606842041  s.\n"
     ]
    }
   ],
   "source": [
    "it = 10\n",
    "max_time = 8000\n",
    "\n",
    "np.random.seed(it)\n",
    "hp = multivariate_exponential_hawkes(mu, alpha, beta, max_time=max_time)\n",
    "hp.simulate()\n",
    "hp_times = hp.timestamps\n",
    "\n",
    "pp = multivariate_exponential_hawkes(noise * np.ones((1,1)), 0*alpha, beta, max_time=max_time)\n",
    "pp.simulate()\n",
    "pp_times = pp.timestamps\n",
    "\n",
    "idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "K = int(parasited_times.shape[0])\n",
    "#K = int(K*np.log(K))\n",
    "\n",
    "start_time = time.time()\n",
    "periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "end_time = time.time()\n",
    "print(\"In :\", end_time - start_time, \" s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfdaa712-e063-4344-b7dd-83aa358e3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, True, True]\n",
      "[1.64644051 2.1455681  1.80829013]\n",
      "here [1.64644051 2.1455681  1.80829013] [0.56150352 0.09228219 0.23058958]\n",
      "here [1.08493699 2.05328591 1.57770055] [0.52879787 0.06130022 0.21652155]\n",
      "here [1.0000000e-16 1.9756947e+00 1.0000000e-16] [-1.33157242e+32 -1.15128011e+15 -5.72524741e+31]\n",
      "here [0.72329133 2.02742217 1.05180037] [0.1315713  0.01904404 0.04538521]\n",
      "here [0.57999727 2.00747925 0.96894295] [-0.27027391 -0.00468814 -0.1234331 ]\n",
      "here [0.66915772 2.01988814 1.02049851] [ 0.00983817  0.01077901 -0.00595953]\n",
      "here [0.63721512 2.00545436 1.09023356] [ 0.00160463  0.00925812 -0.00728758]\n",
      "here [0.5187005  1.93390662 1.38504546] [-0.00697515  0.00500405 -0.00047854]\n",
      "here [0.56204615 1.7997765  1.30775839] [0.00300663 0.00577948 0.00234926]\n",
      "here [1.02441856e+00 1.00000000e-16 4.92433612e-01] [-1.46576339e-01 -3.05869404e-13 -7.32881696e-02]\n",
      "here [0.57349511 1.75521161 1.28756985] [0.00411038 0.00583036 0.00269117]\n",
      "here [0.79895684 0.87760581 0.89000173] [-0.01777077 -0.00698276 -0.00380618]\n",
      "here [0.73189617 1.23565691 0.99447496] [-0.00022684  0.0037378   0.00060175]\n",
      "here [0.77165702 1.02336533 0.93253188] [-0.0095507  -0.00131166 -0.00151857]\n",
      "here [0.80341515 1.00464812 0.86264811] [-0.01163665 -0.00106153 -0.00331082]\n",
      "here [0.89667303 0.9309337  0.67780425] [-0.00723083 -0.00045406 -0.00275155]\n",
      "here [0.9432399  0.8904024  0.59145912] [-0.00231761 -0.0002796  -0.00084811]\n",
      "here [0.96208876 0.87833511 0.5561847 ] [-8.03047224e-05 -1.23057930e-05  1.48785515e-06]\n",
      "here [0.96593517 0.87540822 0.54864516] [ 2.42827531e-05 -1.09958387e-05  1.92063508e-05]\n",
      "In:  336.25678396224976  sec.\n"
     ]
    }
   ],
   "source": [
    "estim = univariate_estimator_bfgs((1, 0.5))\n",
    "start_time = time.time()\n",
    "res = estim.fit(periodogram, max_time)\n",
    "end_time = time.time()\n",
    "print(\"In: \", end_time-start_time, \" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52f495e8-f798-4d8c-aa7d-740953a86315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4948421 , 0.86929579, 0.50115099])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "res # 165, 0.94033425, 0.95709814, 0.61751876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18b8c934-20b2-4909-8abc-9d44766be080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:  160.27114534378052  sec.\n"
     ]
    }
   ],
   "source": [
    "mask = np.array([[False, True],\n",
    "                 [True, False]])\n",
    "estim_red = multivariate_estimator_bfgs(mask=mask)\n",
    "start_time = time.time()\n",
    "res_red = estim_red.fit(periodogram, max_time)\n",
    "end_time = time.time()\n",
    "print(\"In: \", end_time-start_time, \" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a59e2cc2-1341-45a5-9425-0738184d3409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 17.131985185334354\n",
       "        x: [ 1.531e+00  1.382e+00  3.512e-01  4.120e-01  1.091e+00\n",
       "             1.534e+00  1.000e-16]\n",
       "      nit: 55\n",
       "      jac: [ 5.150e-10  1.164e-09 -5.642e-10  8.100e-09  4.045e-11\n",
       "             1.396e-09  2.012e-03]\n",
       "     nfev: 91\n",
       "     njev: 91\n",
       " hess_inv: <7x7 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13655143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----[[8.04391699e-01 7.07924065e-01 7.70970933e-01 1.16643960e+00\n",
      "  6.60687520e-01]\n",
      " [1.46170525e+00 1.72482212e+00 2.35983817e-01 1.97789173e+00\n",
      "  1.00000000e-16]\n",
      " [3.91540886e-01 5.27518394e-01 1.09868181e+00 1.22473443e+00\n",
      "  1.05261324e+00]\n",
      " [8.68772653e-01 1.00339625e+00 4.77232705e-01 2.23202514e+00\n",
      "  5.98577835e-01]\n",
      " [1.50297040e+00 1.49331815e+00 3.20984519e-01 1.58413529e+00\n",
      "  1.00000000e-16]]\n",
      "[1.00587618 1.0913958  0.58077076 1.63704524 0.46237572]\n"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool, cpu_count\n",
    "# Reduced model estimation (parallel) Good\n",
    "\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, None), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.uniform(0, 3, 5)\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll_single,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations_max = np.array(p.map(job, range(repetitions)))\n",
    "print(estimations_max)\n",
    "print(estimations_max.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b0011f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[1.41159461e+00 1.29973177e+00 1.00000000e-16 2.68702085e-02\n",
      "  4.02243830e-01 5.01557528e-02 2.95385583e+00 1.22506070e+00\n",
      "  1.00000000e-16]\n",
      " [1.40050260e+00 1.72473962e+00 1.00000000e-16 2.95677902e-02\n",
      "  2.36041570e-01 1.00000000e-16 3.61299155e-01 1.97690699e+00\n",
      "  1.00000000e-16]\n",
      " [1.33950023e+00 1.46226425e+00 6.75674759e-02 1.00000000e-16\n",
      "  2.75144591e-01 7.60037305e-02 4.30800960e+00 1.32612993e+00\n",
      "  1.00000000e-16]\n",
      " [8.69599370e-01 1.00414837e+00 1.00000000e-16 1.00000000e-16\n",
      "  4.76795689e-01 4.22529772e-05 8.45508432e-01 2.23188091e+00\n",
      "  5.97752887e-01]\n",
      " [1.46935398e+00 1.48755953e+00 3.28564845e-03 1.08483357e-02\n",
      "  3.22241590e-01 1.00000000e-16 1.32052422e+01 1.57679922e+00\n",
      "  6.23558479e-03]]\n",
      "[1.29811016 1.39568871 0.01417062 0.01345727 0.34249345 0.02524035\n",
      " 4.33478304 1.66735555 0.12079769]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) good\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    \n",
    "    init_a = np.random.chisquare(3, dim*2 + 1)\n",
    "\n",
    "    a = np.random.chisquare(3, (dim, dim))\n",
    "    radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    init_alpha = a * div / (radius)\n",
    "\n",
    "    init = np.concatenate((init_a[0:2].ravel(), init_alpha.ravel(), init_a[2:].ravel()))\n",
    "    \n",
    "    periodogram = fast_multi_periodogram(K, parasited_times, max_time)\n",
    "    \n",
    "    res = minimize(grad_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=True,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "start_time = time.time()\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)\n",
    "\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc38810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----|\n",
      "|-----|\n",
      " Done\n",
      "[[9.45959446e-01 1.79370733e+00 1.00000000e-16 2.60740057e-01\n",
      "  2.89011036e-02 7.49201763e-02 1.22102990e+00 3.26424047e+00\n",
      "  1.00000000e-16]\n",
      " [4.41349857e-01 1.40067929e+00 1.00000000e-16 2.48707815e-01\n",
      "  1.00000000e-16 1.00000000e-16 1.98396551e+00 5.35961373e-01\n",
      "  6.70504703e-01]\n",
      " [7.69808394e-01 1.43343025e+00 7.87493824e-02 1.54809560e-01\n",
      "  1.00000000e-16 1.53710342e-01 3.11169456e+00 8.27501565e-01\n",
      "  3.17606196e-01]\n",
      " [1.09144610e+00 1.87479322e+00 1.00000000e-16 1.85547704e-01\n",
      "  1.00000000e-16 7.06698514e-02 2.54439117e+00 1.18621304e+00\n",
      "  1.00000000e-16]\n",
      " [1.04514436e+00 1.79623517e+00 1.00000000e-16 2.30808676e-01\n",
      "  1.00000000e-16 9.12814046e-02 1.68943754e+00 3.72968375e-01\n",
      "  1.00000000e-16]]\n",
      "[0.85874163 1.65976905 0.01574988 0.21612276 0.00578022 0.07811635\n",
      " 2.11010374 1.23737696 0.19762218]\n"
     ]
    }
   ],
   "source": [
    "# Full model estimation (parallel) bad\n",
    "max_time = 1000\n",
    "repetitions = 5\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    K = int(np.log(K) * K)\n",
    "    init = np.random.rand(9)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram_bad(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(5) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "print(estimations)\n",
    "print(estimations.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f539fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------------------|\n",
      "|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n",
      "/Users/alisdair/PycharmProjects/hawkes-inhibition/venv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:353: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------|\n",
      " Done\n"
     ]
    }
   ],
   "source": [
    "# Without noise model estimation (parallel)\n",
    "max_time = 3000\n",
    "repetitions = 50\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), \n",
    "          (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    \n",
    "    #init_a = np.random.uniform(0,3, dim*2)\n",
    "    #a = np.random.uniform(0,3, (dim,dim))\n",
    "    #radius = np.max(np.abs(np.linalg.eig(a)[0]))\n",
    "    #div = np.random.uniform(1e-16, 1 - 1e-16)\n",
    "    #init_alpha = a * div / (radius)\n",
    "    \n",
    "    #init = np.concatenate((init_a[0:dim].ravel(), init_alpha.ravel(), init_a[dim:].ravel()))\n",
    "    init = np.random.rand(8)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(4) as p:\n",
    "    estimations_nonoised_model = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "#print(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d142f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "explanation = \"Estimations for Scenario (Single).\"\n",
    "explanation += \" First is explanation, second is estimations in non-noised model,\"\n",
    "explanation += \" Dimensions (repetitions, parameters).\"\n",
    "explanation\n",
    "toSave = (explanation, estimations_nonoised_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d2bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('estimationsSingleNonNoisedModel2410.pkl', 'wb') as file:\n",
    "    pickle.dump(toSave, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
